{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cc828c",
   "metadata": {},
   "source": [
    "---\n",
    "# Modelling hippocampal neurons of animals navigating in VR with recurrent neural networks\n",
    "### Marco P. Abrate, Daniel Liu\n",
    "---\n",
    "\n",
    "##### Outline\n",
    "Rat simulation:\n",
    "- Motion model (RatInABox)\n",
    "- Environment design (Blender)\n",
    "- Simulated rat vision (ratvision)\n",
    "\n",
    "Vision autoencoder\n",
    "\n",
    "Hippocampus model (RNN):\n",
    "- RNN definition\n",
    "- Data loading\n",
    "- Training\n",
    "\n",
    "Hidden state representations analysis:\n",
    "- Rate maps\n",
    "- Polar maps\n",
    "- Quantitive metrics\n",
    "- Comparison with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124450f7",
   "metadata": {},
   "source": [
    "---\n",
    "## **Part 4: Extracting Neural Representations from an RNN**\n",
    "In this notebook, we will write code to extract representations from the **RNN hidden states**. These includes:\n",
    "- Rate maps\n",
    "- Polar maps\n",
    "- Quantitative metrics\n",
    "- Comparison with _in vivo_ data\n",
    "\n",
    "Before starting this notebook, make sure you have:\n",
    "- trajectory data from part 1, including speed and rotational speed\n",
    "- embedded vision data from the Vision Autoencoder we trained in part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00121d04",
   "metadata": {},
   "source": [
    "### **0. Install and import dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c292c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp310-cp310-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   --- ----------------------------------- 21.0/216.1 MB 102.0 MB/s eta 0:00:02\n",
      "   ------- ------------------------------- 44.3/216.1 MB 108.5 MB/s eta 0:00:02\n",
      "   ------------ -------------------------- 67.9/216.1 MB 108.2 MB/s eta 0:00:02\n",
      "   ---------------- ---------------------- 92.3/216.1 MB 109.0 MB/s eta 0:00:02\n",
      "   -------------------- ----------------- 115.1/216.1 MB 109.7 MB/s eta 0:00:01\n",
      "   ------------------------ ------------- 138.9/216.1 MB 109.6 MB/s eta 0:00:01\n",
      "   ---------------------------- --------- 161.5/216.1 MB 109.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 185.9/216.1 MB 111.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 209.2/216.1 MB 111.4 MB/s eta 0:00:01\n",
      "   -------------------------------------  216.0/216.1 MB 111.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- 216.1/216.1 MB 102.3 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.1-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 90.4 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.1-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 138.8 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 97.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "\n",
      "   ----------------------------------------  0/10 [mpmath]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   ---- -----------------------------------  1/10 [sympy]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   -------- -------------------------------  2/10 [networkx]\n",
      "   ---------------- -----------------------  4/10 [fsspec]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   ---------------------------- -----------  7/10 [torch]\n",
      "   -------------------------------- -------  8/10 [torchvision]\n",
      "   -------------------------------- -------  8/10 [torchvision]\n",
      "   -------------------------------- -------  8/10 [torchvision]\n",
      "   ------------------------------------ ---  9/10 [torchaudio]\n",
      "   ---------------------------------------- 10/10 [torchaudio]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1\n",
      "Requirement already satisfied: numpy in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages (from scipy) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac87109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    \n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8a4ca",
   "metadata": {},
   "source": [
    "### **1. Load test data and trained RNN**\n",
    "\n",
    "In the first step, we will define the RNN in Part 3 of this tutorial and load the trained weights. We will also need the test embeddings and auxiliary variables, with which we will use to compute the rate maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6521f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, do not modify it.\n",
    "\n",
    "def create_multiple_subsampling(data, stride, is_velocity=False):\n",
    "    new_length = data.shape[0]//stride if not is_velocity else data.shape[0]//stride-1\n",
    "    data_multisubs = np.zeros(\n",
    "        (stride, new_length, data.shape[1]),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    for start_idx in range(stride):\n",
    "        if is_velocity:\n",
    "            if start_idx < stride-1:\n",
    "                data_multisubs[start_idx] = data[start_idx+1:start_idx-stride+1].reshape(\n",
    "                    new_length, stride, -1\n",
    "                ).sum(axis=1)\n",
    "            else:\n",
    "                data_multisubs[start_idx] = data[start_idx+1:].reshape(\n",
    "                    new_length, stride, -1\n",
    "                ).sum(axis=1)\n",
    "        else:\n",
    "            data_multisubs[start_idx] = data[start_idx::stride]\n",
    "    return data_multisubs\n",
    "\n",
    "class RNNCell(torch.nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, input_bias, hidden_bias):\n",
    "        super(RNNCell, self).__init__()\n",
    "\n",
    "        self.in2hidden = torch.nn.Linear(n_inputs, n_hidden, bias=input_bias)\n",
    "        self.hidden2hidden = torch.nn.Linear(n_hidden, n_hidden, bias=hidden_bias)\n",
    "\n",
    "        self.activation_fn = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        igates = self.in2hidden(x)\n",
    "        hgates = self.hidden2hidden(hidden)\n",
    "        return self.activation_fn(igates + hgates)\n",
    "\n",
    "\n",
    "class RNNModule(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, device, n_inputs, n_hidden,\n",
    "        input_bias, hidden_bias\n",
    "    ):\n",
    "        super(RNNModule, self).__init__()\n",
    "\n",
    "        self.rnn_cell = RNNCell(n_inputs, n_hidden, input_bias, hidden_bias)\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: [BATCH SIZE, TIME, N_FEATURES]\n",
    "        # hidden: [BATCH SIZE, N_HIDDEN]\n",
    "        \n",
    "        output = torch.zeros(x.shape[0], x.shape[1], self.n_hidden).to(self.device)\n",
    "\n",
    "        if hidden is None:\n",
    "            h_out = torch.zeros(x.shape[0], self.n_hidden) # initialize hidden state\n",
    "            h_out = h_out.to(self.device)\n",
    "        else:\n",
    "            h_out = hidden\n",
    "\n",
    "        window_size = x.shape[1]\n",
    "\n",
    "        # loop over time\n",
    "        for t in range(window_size):\n",
    "            x_t = x[:,t,...]\n",
    "            h_out = self.rnn_cell(x_t, h_out)\n",
    "            output[:,t,...] = h_out\n",
    "\n",
    "        # return all outputs, and the last hidden state\n",
    "        return output, h_out\n",
    "\n",
    "class PredictiveRNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        device, n_inputs, n_hidden, n_outputs, bias=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = RNNModule(\n",
    "            device, n_inputs, n_hidden,\n",
    "            input_bias=bias, hidden_bias=bias\n",
    "        )\n",
    "\n",
    "        self.linear_layer = torch.nn.Linear(n_hidden, n_outputs, bias=bias)\n",
    "\n",
    "    def inputs2hidden(self, inputs, hidden):\n",
    "        \"\"\" Encodes the input tensor into a latent representation.\n",
    "\n",
    "        Args:\n",
    "            x: [BATCH SIZE, TIME, CHANNELS, HEIGHT, WIDTH]\n",
    "        \"\"\"\n",
    "        \n",
    "        if hidden is not None:\n",
    "            return self.rnn(inputs, hidden[None, ...])[0]\n",
    "        else:\n",
    "            return self.rnn(inputs)[0]\n",
    "\n",
    "    def hidden2outputs(self, hidden):\n",
    "        return self.linear_layer(hidden)\n",
    "    \n",
    "    def forward(self, inputs, hidden=None):\n",
    "        hidden_new = self.inputs2hidden(inputs, hidden)\n",
    "\n",
    "        output = self.hidden2outputs(hidden_new)\n",
    "\n",
    "        return output, hidden_new[:,-1,:]\n",
    "\n",
    "class SensoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, embs, vels, rot_vels, pos, hds, tsteps=9):\n",
    "        '''\n",
    "        The initialisation function for the SensoryDataset class.\n",
    "        At initialisation, all embeddings are converted to tensors.\n",
    "        Args:\n",
    "            embs: The visual embeddings of shape (N, T, D)\n",
    "            vels: The speed signals of shape (N, T-1, 1)\n",
    "            rot_vels: The rotational velocities of shape (N, T-1, 1)\n",
    "            pos: The positions of shape (N, T, 2)\n",
    "            hds: The headings of shape (N, T, 1)\n",
    "            tsteps: The number of time steps for each batch.\n",
    "                By default, this is set to 9 i.e. we use the sensory input from steps 1 to 9          \n",
    "        '''\n",
    "        self.embs = torch.from_numpy(embs)\n",
    "        self.vels = torch.from_numpy(vels)\n",
    "        self.rot_vels = torch.from_numpy(rot_vels)\n",
    "        self.pos = torch.from_numpy(pos)\n",
    "        self.hds = torch.from_numpy(hds)\n",
    "        \n",
    "        self.tsteps = tsteps\n",
    "    \n",
    "    def __len__(self):\n",
    "        # COMPLETE THE CODE HERE: how many samples are in the dataset?\n",
    "        return self.embs.shape[1] // self.tsteps - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        This function returns a batch of sensory inputs and the corresponding future sensory inputs.\n",
    "        Args:\n",
    "            idx: The index of the sample to return. idx will be automatically generated by the DataLoader.\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        vels, rot_vels, pos, hds, embs_labels = [], [], [], [], []\n",
    "\n",
    "        start_idx, end_idx = idx*self.tsteps, (idx + 1)*self.tsteps\n",
    "\n",
    "        embs = self.embs[:, start_idx:end_idx]\n",
    "\n",
    "        vels = self.vels[:, start_idx:end_idx]\n",
    "        rot_vels = self.rot_vels[:, start_idx:end_idx]\n",
    "        pos = self.pos[:, start_idx:end_idx]\n",
    "        hds = self.hds[:, start_idx:end_idx]\n",
    "\n",
    "        embs_labels = self.embs[:, start_idx+1 : end_idx+1]\n",
    "        \n",
    "        return embs, vels, rot_vels, pos, hds, embs_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17556bd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\adult\\\\exp_dim0.635_fps10_s720_seed21\\\\vision_embeddings.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trial_paths)):\n\u001b[0;32m     11\u001b[0m     tp \u001b[38;5;241m=\u001b[39m trial_paths[idx]\n\u001b[0;32m     12\u001b[0m     repr_embeddings\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m---> 13\u001b[0m         create_multiple_subsampling(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvision_embeddings.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, stride\u001b[38;5;241m=\u001b[39mSTRIDE)\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     15\u001b[0m     repr_vel\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     16\u001b[0m         create_multiple_subsampling(\n\u001b[0;32m     17\u001b[0m             np\u001b[38;5;241m.\u001b[39mload(tp \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mriab_simulation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvelocities.npy\u001b[39m\u001b[38;5;124m'\u001b[39m), stride\u001b[38;5;241m=\u001b[39mSTRIDE, is_velocity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         )\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m     repr_rotvel\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     21\u001b[0m         create_multiple_subsampling(\n\u001b[0;32m     22\u001b[0m             np\u001b[38;5;241m.\u001b[39mload(tp \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mriab_simulation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrot_velocities.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m     23\u001b[0m             stride\u001b[38;5;241m=\u001b[39mSTRIDE, is_velocity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m         )\n\u001b[0;32m     25\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\cns_tuts\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:451\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    449\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    452\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\adult\\\\exp_dim0.635_fps10_s720_seed21\\\\vision_embeddings.npy'"
     ]
    }
   ],
   "source": [
    "# let's load the test data and process it into a dataloader, just like we did in the last part.\n",
    "\n",
    "STRIDE = 10\n",
    "d = './data/adult'\n",
    "trial_paths = sorted([p for p in Path(d).iterdir() if 'exp' in p.name])\n",
    "\n",
    "repr_embeddings = []\n",
    "repr_vel, repr_rotvel, repr_pos, repr_hds = [], [], [], []\n",
    "\n",
    "for idx in range(20, len(trial_paths)):\n",
    "    tp = trial_paths[idx]\n",
    "    repr_embeddings.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'vision_embeddings.npy'), stride=STRIDE)\n",
    "    )\n",
    "    repr_vel.append(\n",
    "        create_multiple_subsampling(\n",
    "            np.load(tp / 'riab_simulation' / 'velocities.npy'), stride=STRIDE, is_velocity=True\n",
    "        )\n",
    "    )\n",
    "    repr_rotvel.append(\n",
    "        create_multiple_subsampling(\n",
    "            np.load(tp / 'riab_simulation' / 'rot_velocities.npy')[..., None],\n",
    "            stride=STRIDE, is_velocity=True\n",
    "        )\n",
    "    )\n",
    "    repr_pos.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'riab_simulation' / 'positions.npy'), stride=STRIDE)\n",
    "    )\n",
    "    repr_hds.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'riab_simulation' / 'thetas.npy')[..., None], stride=STRIDE)\n",
    "    )\n",
    "\n",
    "repr_embeddings = np.concatenate(repr_embeddings, axis=0)\n",
    "repr_vel = np.concatenate(repr_vel, axis=0)\n",
    "repr_rotvel = np.concatenate(repr_rotvel, axis=0)\n",
    "repr_pos = np.concatenate(repr_pos, axis=0)\n",
    "repr_hds = np.concatenate(repr_hds, axis=0)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    SensoryDataset(\n",
    "        repr_embeddings, repr_vel, repr_rotvel, repr_pos, repr_hds\n",
    "    ), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5283f7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's re-define the PredictiveRNN model, just like we did in the last part\n",
    "# and load the trained weights\n",
    "\n",
    "visual_embedding_dim = repr_embeddings.shape[-1]\n",
    "motion_signal_dim = repr_vel.shape[-1] + repr_rotvel.shape[-1]\n",
    "trained_rnn_weights ='./rnn.pth'\n",
    "\n",
    "rnn = PredictiveRNN(\n",
    "    DEVICE,\n",
    "    n_inputs=visual_embedding_dim + motion_signal_dim,\n",
    "    n_hidden=500,\n",
    "    n_outputs=visual_embedding_dim\n",
    ").to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "# load the trained weights\n",
    "rnn.load_state_dict(torch.load(trained_rnn_weights, map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd1748",
   "metadata": {},
   "source": [
    "### **2. Get hidden states from trained RNN**\n",
    "\n",
    "We had written a function named ```evaluate_rnn()```, when the parameter ```for_ratemaps``` is set to ```True```, the function will return a dictionary containing the hidden staes, positions, velocities, etc. at each step for the convenience of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826cf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42660, 500), (42660, 2), (42660, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import evaluate_rnn\n",
    "d = evaluate_rnn(DEVICE, rnn, dataloader, loss_fn, for_ratemaps=True)\n",
    "\n",
    "hidden_states = d['hidden_states']\n",
    "hidden_states = hidden_states.reshape(-1, hidden_states.shape[-1])\n",
    "positions = d['positions']\n",
    "positions = positions.reshape(-1, positions.shape[-1])\n",
    "head_directions = d['head_directions']\n",
    "head_directions = head_directions.reshape(-1, head_directions.shape[-1])\n",
    "\n",
    "hidden_states.shape, positions.shape, head_directions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ba3a1",
   "metadata": {},
   "source": [
    "### **3. Rate maps**\n",
    "\n",
    "The **rate map** of a neuron is essentially the average activity of a neuron across an environment. This is, by design, a continuous distribution.\n",
    "\n",
    "Computationally, this requires us to discritise the environment into smallers 'bins', then compute the average activity at each small bin. The function below computes such average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3205d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# The following function discritise the environment into smaller bins.\n",
    "\n",
    "def bin_data(data, n_bins, limits, weights=[]):\n",
    "    \"\"\"\n",
    "    Creates an N-dimensional histogram of data using n_bins between limits.\n",
    "    If weights is provided, it creates a weighted histogram.\n",
    "    \n",
    "    Args:\n",
    "        data: The data to be binned of shape (n_samples, n_dim).\n",
    "        n_bins: The number of bins for each dimension.\n",
    "        limits (list of tuples): The lower and upper limits for each dimension.\n",
    "        weights: 1D array-like, optional\n",
    "            The weights for the counts in the histogram.\n",
    "    \n",
    "    Returns:\n",
    "        binned_data: The N-dimensional histogram of data.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_dim = data.shape[-1]\n",
    "    if np.size(n_bins) < n_dim:\n",
    "        n_bins = np.repeat(n_bins, n_dim)\n",
    "    \n",
    "    bins = []\n",
    "    if n_dim == 1:\n",
    "        bins.append(np.linspace(limits[0], limits[1], n_bins+1))\n",
    "    else:\n",
    "        for i in range(n_dim):\n",
    "            bins.append(np.linspace(limits[i][0], limits[i][1], n_bins[i]+1))\n",
    "        \n",
    "    if len(weights) == 0:\n",
    "        hst = np.histogramdd(data, bins=bins)\n",
    "    else:\n",
    "        hst = np.histogramdd(data, bins=bins, weights=weights, density=False)\n",
    "\n",
    "    return hst[0]\n",
    "\n",
    "\n",
    "# The following function calculates the average activity of each such bin, that is, the rate map.\n",
    "\n",
    "def compute_rate_maps(\n",
    "    hidden_states:np.array, pos:np.array, sigma:float,\n",
    "    limits=[(0, 0.635),(0, 0.635)], n_bins:int=25\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the smooth rate map for each neuron based on the given hidden states and trajectory.\n",
    "\n",
    "    Args:\n",
    "        hidden_states (np.array): (samples, n_hidden) Array of hidden states for each neuron.\n",
    "        pos (np.array): (samples, 2) Array of (x,y) positions.\n",
    "        sigma (float): Standard deviation of the Gaussian filter.\n",
    "        limits (list): Lower and upper limits of the positions.\n",
    "        n_bins (float): Number of bins for the positions.\n",
    "\n",
    "    Returns:\n",
    "        rate_maps (np.array): Smoothed rate maps for each neuron of shape (n_hidden, n_bins, n_bins).\n",
    "        occupancy_smoothed (np.array): Smoothed occupancy map of shape (n_bins, n_bins).\n",
    "    \"\"\"\n",
    "    \n",
    "    occupancy = bin_data(pos, n_bins=n_bins, limits=limits)\n",
    "    if sigma > 0:\n",
    "        occupancy = gaussian_filter(occupancy,sigma)\n",
    "\n",
    "    n_cells = hidden_states.shape[1]\n",
    "    rate_maps = np.empty(shape=(n_cells,occupancy.shape[0],occupancy.shape[1]))\n",
    "    for i in range(n_cells):\n",
    "        activations = bin_data(pos, n_bins=n_bins, limits=limits, weights=hidden_states[:,i])\n",
    "        if sigma > 0: \n",
    "            activations = gaussian_filter(activations, sigma)\n",
    "        rate_maps[i,:,:] = np.divide(\n",
    "            activations, occupancy, where=occupancy!=0,\n",
    "            out=np.nan*np.ones_like(activations)\n",
    "        )\n",
    "    \n",
    "    # flip y and swap x and y coordinates so that they appear correctly in the image\n",
    "    rate_maps = np.flip(rate_maps, axis=-1)\n",
    "    rate_maps = np.transpose(rate_maps, (0, 2, 1))\n",
    "\n",
    "    return rate_maps, occupancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee70a0",
   "metadata": {},
   "source": [
    "In the real brain, neuron firings are stochastic. This means there is a lot of noise in the process, and the average activity of each bin is a crude (but unbiased) estimate of the real tuning curve, depending on the amount of data provided.\n",
    "\n",
    "Often, we make the assumption that a neuron's activity do not change too much in neighbouring bins. To make our rate maps look smoother, it is customary to apply **Gaussian smoothing** to the rate maps. This is easily achievable with packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb44229",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_maps, occupancy = compute_rate_maps(hidden_states, positions, sigma=0)\n",
    "\n",
    "rate_maps_smooth, occupancy_smooth = compute_rate_maps(hidden_states, positions, sigma=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de946776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAG1CAYAAAAstr8LAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXP5JREFUeJzt3Xd4VHX6/vE7CcmkkdACIdRQpBcXlaYCggRUFAURxBUQERFZERVlLYANsay6iiBfO5YVFLGsYqFZaAqiYEFAUBDpppCYhCTn9we/zJ4hCWSelInk/bquXMrJufP5zJnynGfOmTNBjuM4AgAAAABIkoIDPQEAAAAAqEhokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxoklAh7NixQ0FBQXr44YfLfKwXXnhBQUFB2rFjR5mPhf/JycnR5MmT1aBBAwUHB2vgwIGBnhKASiQoKEjXX399mY+zfPlyBQUFafny5WU+Fnw99NBDatKkiUJCQtSxY8dATwd/cTRJpWTatGkKCgrSgQMHCv1927Zt1bNnz/KdVAX0/vvva9q0aYGeRrHk36f5P6GhoWrcuLH+8Y9/KDk52fQ3d+/erWnTpmnDhg2lOtf8JjMoKEj33ntvoesMHz5cQUFBio6OLtWxi+u5557TQw89pMGDB+vFF1/UjTfeWKbj9ezZU0FBQRowYECB35VnUx5oe/fu1ahRo1S7dm1FRETob3/7mxYsWBDoaaGC27hxowYPHqxGjRopPDxc9erV07nnnqsnnngi0FM7rpUrV2ratGnm1+jylP+GXf5PlSpVVK9ePY0cOVK//fab6W9mZGRo2rRpZdKg5c/z6quvLvT3t99+u3edovaFytJHH32kyZMnq3v37nr++ed1//33l+l4I0eOVFBQkNq3by/HcQr8vrya8kA7fPiwJk6cqPr168vj8ahVq1aaPXt2oKdVKqoEegKoXN5//33NmjXrL9MoSdLs2bMVHR2t9PR0LVmyRE888YTWr1+vzz//3O+/tXv3bk2fPl2NGzcuk3e5wsPD9dprr+mOO+7wWZ6enq63335b4eHhpT5mcS1dulT16tXTo48+Wq7jvvfee1q3bp06depUruNWBKmpqTrzzDO1d+9e3XDDDYqPj9f8+fM1ZMgQvfLKK7r88ssDPUVUQCtXrlSvXr3UsGFDjRkzRvHx8dq5c6dWr16txx9/XBMmTAj0FIu0cuVKTZ8+XSNHjlS1atUCPZ1iufvuu5WYmKjMzEytXr1aL7zwgj7//HNt2rTJ79fsjIwMTZ8+XZLK5I3Z8PBwvfnmm3rqqacUFhbm87vXXntN4eHhyszMLPVxi2Pp0qUKDg7Ws88+W2BuZWnjxo1auHChBg0aVG5jVhS5ublKSkrSV199pfHjx6t58+b68MMPdd111+mPP/7QP//5z0BPsURokoATGDx4sGrVqiVJGjt2rIYOHarXX39da9eu1RlnnBHg2fk677zztHDhQn3zzTfq0KGDd/nbb7+t7Oxs9evXT0uXLg3I3Pbt21eqOy15eXnKzs4+7k5Ew4YNlZaWpunTp+udd94ptbFLIj09XVFRUeUy1tNPP62tW7dqyZIlOueccyRJ48aNU5cuXXTTTTdp8ODB5bozgb+G++67T7Gxsfryyy8LPGf37dsXmEmdxPr376/TTjtNknT11VerVq1amjlzpt555x0NGTIkwLPz1a9fP73zzjv64IMPdNFFF3mXr1y5Utu3b9egQYP05ptvBmRu+/btU0RERKm9pjmOo8zMTEVERBS5TkREhBo0aKC7775bl1xyiYKCgkpl7JIozxqzcOFCrVy5Us8++6yuuuoqSUdrzODBg3XPPffo6quvVu3atctlLmWB0+0CJP+c5fnz5+u+++5T/fr1FR4ert69e2vr1q3F+htfffWVkpKSVKtWLUVERCgxMdH7IJV8TymaNWuWmjRposjISPXt21c7d+6U4zi65557VL9+fUVEROiiiy7SoUOHCozz1FNPqU2bNvJ4PEpISND48eMLPZVhwYIF6tSpkyIiIlSrVi1dccUVPqcMjBw5UrNmzZIkn1MMjjV37lw1bdpUHo9Hp59+ur788ssC6/z4448aPHiwatSoofDwcJ122mmF7gR/9913OueccxQREaH69evr3nvvVV5eXrG2b1HOOussSdK2bdu8yw4dOqSbb75Z7dq1U3R0tGJiYtS/f39988033nWWL1+u008/XZI0atQo7+1/4YUXvOusWbNG/fr1U2xsrCIjI9WjRw998cUXxZ5b165dlZiYqFdffdVn+SuvvKJ+/fqpRo0aBTJvv/22zj//fCUkJMjj8ahp06a65557lJub67Nez5491bZtW61bt07dunXzPubmzJlz3DnlPw6XLVum7777znu7808HSU9P10033aQGDRrI4/GoRYsWevjhhwucvpB/6sIrr7zifTwuXrz4uGNXrVpVN954o959912tX7/+uOtKUnJysiZOnOidS7NmzTRz5kyfx0xRnzfIv53u+3PkyJGKjo7Wtm3bdN5556lq1aoaPny46XYvWrRIbdu2lcfjUZs2bU542yXps88+U1xcnLdBkqTg4GANGTJEe/bs0YoVK074N1D5bNu2TW3atCn0TY1jd3jyH58LFixQ69atFRERoa5du2rjxo2SjjbqzZo1U3h4uHr27FnoZ0FPVDvyLV26VGeddZaioqJUrVo1XXTRRfrhhx+8v582bZpuueUWSVJiYqL3tebYMYvzXPrtt9901VVXqU6dOt71nnvuuQLr7dq1SwMHDlRUVJRq166tG2+8UVlZWQXW80dhNSY7O1t33XWXOnXqpNjYWEVFRemss87SsmXLvOvs2LFDcXFxkqTp06d7b7/7zI3i1s6i1KtXT2effXahNaZdu3Zq27Ztgcxnn32mSy+9VA0bNpTH41GDBg1044036s8///RZL//18ueff1ZSUpKioqKUkJCgu+++u9DT2dyCgoL0/PPPKz09vUBtzcnJ0T333OPdr2jcuLH++c9/FrifGjdurAsuuEAffvihTjvtNEVEROjpp58+7rjBwcG644479O233+qtt9467rqSlJWVpalTp6pZs2bebTF58mSfuRRWS9y3031/5n8s4Pvvv9fll1+u6tWr68wzzzTd7s8//1xnnHGGwsPD1aRJE7300ksnvD2fffaZJGno0KE+y4cOHarMzEy9/fbbJ/wbFRlHkgLsgQceUHBwsG6++WalpKTowQcf1PDhw7VmzZrj5vbt26e+ffsqLi5Ot912m6pVq6YdO3Zo4cKFBdZ95ZVXlJ2drQkTJujQoUN68MEHNWTIEJ1zzjlavny5br31Vm3dulVPPPGEbr75Zp9CMG3aNE2fPl19+vTRuHHjtHnzZs2ePVtffvmlvvjiC4WGhko6em71qFGjdPrpp2vGjBnau3evHn/8cX3xxRf6+uuvVa1aNY0dO1a7d+/Wxx9/rHnz5hV6u1599VWlpaVp7NixCgoK0oMPPqhLLrlEP//8s3es7777Tt27d1e9evV02223KSoqSvPnz9fAgQP15ptv6uKLL5Yk7dmzR7169VJOTo53vblz5x73XaHiyC+41atX9y77+eeftWjRIl166aVKTEzU3r179fTTT6tHjx76/vvvlZCQoFatWunuu+/WXXfdpWuuucZbCLt16ybp6A5A//791alTJ02dOlXBwcF6/vnndc455+izzz4r9lGrYcOG6eWXX9YDDzzgPTf8o48+0rx58wrdGXjhhRcUHR2tSZMmKTo6WkuXLtVdd92l1NRUPfTQQz7r/vHHHzrvvPM0ZMgQDRs2TPPnz9e4ceMUFhbm06C7xcXFad68ebrvvvt0+PBhzZgxQ5LUqlUrOY6jCy+8UMuWLdPo0aPVsWNHffjhh7rlllv022+/FTg1b+nSpZo/f76uv/561apVS40bNz7h9rjhhhv06KOPatq0acfdGcjIyFCPHj3022+/aezYsWrYsKFWrlypKVOm6Pfff9djjz12wrEKk5OTo6SkJJ155pl6+OGHFRkZ6fft/vzzz7Vw4UJdd911qlq1qv79739r0KBB+vXXX1WzZs0ix87Kyir08R4ZGSlJWrdunc4991zT7cLJq1GjRlq1apU2bdpU6E7vsT777DO98847Gj9+vCRpxowZuuCCCzR58mQ99dRT3lNvHnzwQV111VU+R7OLUzsk6ZNPPlH//v3VpEkTTZs2TX/++aeeeOIJde/eXevXr1fjxo11ySWX6KefftJrr72mRx991HsGQH7jIBXvubR371516dLF2wDGxcXpgw8+0OjRo5WamqqJEydKkv7880/17t1bv/76q/7xj38oISFB8+bNK/HR+sJqTGpqqp555hkNGzZMY8aMUVpamp599lklJSVp7dq16tixo+Li4jR79myNGzdOF198sS655BJJUvv27SUVv3aeyOWXX64bbrhBhw8fVnR0tHJycrRgwQJNmjSp0FPtFixYoIyMDI0bN041a9bU2rVr9cQTT2jXrl0FPh+Zm5urfv36qUuXLnrwwQe1ePFiTZ06VTk5Obr77ruLnNO8efM0d+5crV27Vs8884yk/9XWq6++Wi+++KIGDx6sm266SWvWrNGMGTP0ww8/FGhsNm/erGHDhmns2LEaM2aMWrRoUaztcc899+juu+/WxRdfXOTRpLy8PF144YX6/PPPdc0116hVq1bauHGjHn30Uf30009atGjRCccqyqWXXqrmzZvr/vvv9zaU/tzurVu3avDgwRo9erRGjBih5557TiNHjlSnTp3Upk2bIsfNyspSSEhIgaN37hozZswY8+0KOAelYurUqY4kZ//+/YX+vk2bNk6PHj28/162bJkjyWnVqpWTlZXlXf744487kpyNGzced7y33nrLkeR8+eWXRa6zfft2R5ITFxfnJCcne5dPmTLFkeR06NDBOXLkiHf5sGHDnLCwMCczM9NxHMfZt2+fExYW5vTt29fJzc31rvfkk086kpznnnvOcRzHyc7OdmrXru20bdvW+fPPP73rvffee44k56677vIuGz9+vFPYwy5/rjVr1nQOHTrkXf722287kpx3333Xu6x3795Ou3btvPN0HMfJy8tzunXr5jRv3ty7bOLEiY4kZ82aNd5l+/btc2JjYx1Jzvbt24vcdo7zv/t08+bNzv79+50dO3Y4zz33nBMREeHExcU56enp3nUzMzN9tlH+bfJ4PM7dd9/tXfbll186kpznn3/eZ928vDynefPmTlJSkpOXl+ddnpGR4SQmJjrnnnvuceeav/0eeughZ9OmTY4k57PPPnMcx3FmzZrlREdHO+np6c6IESOcqKgon2xGRkaBvzd27FgnMjLSZxv36NHDkeQ88sgj3mVZWVlOx44dndq1azvZ2dnHnWOPHj2cNm3a+CxbtGiRI8m59957fZYPHjzYCQoKcrZu3epdJskJDg52vvvuu+OOU9h406dPdyQ569atcxzHd3vlu+eee5yoqCjnp59+8vk7t912mxMSEuL8+uuvjuP877m7bNkyn/Xy/6b7vh0xYoQjybnttttKdLvDwsJ8ln3zzTeOJOeJJ5447jaYMGGCExwc7OzYscNn+dChQx1JzvXXX3/cPCqnjz76yAkJCXFCQkKcrl27OpMnT3Y+/PDDQp/jkhyPx+Pzevr00087kpz4+HgnNTXVuzy/9uSv60/tyH+dOXjwoHfZN9984wQHBztXXnmld9lDDz1U5Ot7cZ9Lo0ePdurWrescOHDAJz906FAnNjbW+5r52GOPOZKc+fPne9dJT093mjVrVuhrxLGef/55R5LzySefOPv373d27tzpvPHGG05cXJzj8XicnTt3etfNycnx2VdwHMf5448/nDp16jhXXXWVd9n+/fsdSc7UqVMLjFfc2lkUSc748eOdQ4cOOWFhYc68efMcx3Gc//73v05QUJCzY8eOQveFCqsxM2bMcIKCgpxffvnFuyz/9XLChAk+8zv//POdsLCwIvev3Plj69uGDRscSc7VV1/ts/zmm292JDlLly71LmvUqJEjyVm8ePEJt8Wx47344ouOJGfhwoXe3+dvr3zz5s1zgoODvbU535w5cxxJzhdffOE4TuG1xP033fdt/vYeNmxYiW/3p59+6l22b98+x+PxODfddNNxt8Ejjzzis7+R77bbbnMkORdccMFx8xUdp9sF2KhRo3w68PyjCz///PNxc/nvrr333ns6cuTIcde99NJLFRsb6/13586dJUlXXHGFqlSp4rM8Ozvbe5rDJ598ouzsbE2cOFHBwf97qIwZM0YxMTH673//K+noaX/79u3Tdddd5/P5kPPPP18tW7b0rlccl112mc+7Z8duj0OHDmnp0qUaMmSI0tLSdODAAR04cEAHDx5UUlKStmzZ4p3/+++/ry5duvgcgYmLi/Oe7lRcLVq0UFxcnBo3bqyrrrpKzZo10wcffOB9p0SSPB6Pdxvl5ubq4MGDio6OVosWLYp1mteGDRu0ZcsWXX755Tp48KD3dqWnp6t379769NNPi32aYJs2bdS+fXu99tprko4enbvooot85uvmPtKQv03POussZWRk6Mcff/RZt0qVKho7dqz332FhYRo7dqz27dundevWFWt+bu+//75CQkL0j3/8w2f5TTfdJMdx9MEHH/gs79Gjh1q3bu33ODfccIOqV6/u/UBzYRYsWKCzzjpL1atX927/AwcOqE+fPsrNzdWnn37q97j5xo0b5/Nvf293nz591LRpU++/27dvr5iYmBO+Tlx99dUKCQnRkCFDtHLlSm3btk0zZszwvot47OkugCSde+65WrVqlS688EJ98803evDBB5WUlKR69eoVejS2d+/ePkd182vMoEGDVLVq1QLL8x+3xa0dv//+uzZs2KCRI0f6nDLcvn17nXvuuXr//feLfdtO9FxyHEdvvvmmBgwYIMdxfF4LkpKSlJKS4n1Nf//991W3bl0NHjzY+/ciIyN1zTXXFHs++XOKi4tTgwYNNHjwYEVFRemdd95R/fr1veu4363Py8vToUOHlJOTo9NOO61YNcaf2nki1atXV79+/XxqTLdu3dSoUaNC13fXmPT0dB04cEDdunWT4zj6+uuvC6zvviJc/tG87OxsffLJJ8Wan1v+Y2PSpEk+y2+66SZJKrB/kpiYqKSkJL/HGT58uJo3b37cUwMXLFigVq1aqWXLlj6Pq/zTod2nTvrr2muv9fm3v7e7devW3v0t6ei+UosWLU5YYy6//HLFxsbqqquu0scff6wdO3Zo7ty5euqppyT99WsMTVI5KuwQbMOGDX3+nd8g/PHHH5KOXlpxz5493p/9+/dLOrqzOGjQIE2fPl21atXSRRddpOeff77Qc6GPHSO/YWrQoEGhy/PH/uWXXySpwOHmsLAwNWnSxPv7otaTpJYtW3p/Xxwn2h5bt26V4zi68847FRcX5/MzdepUSf/7YPEvv/yi5s2bFxijOIfP3d588019/PHHevXVV9WlSxfvh0Pd8vLy9Oijj6p58+byeDyqVauW4uLi9O233yolJeWEY2zZskWSNGLEiAK365lnnlFWVlax/k6+yy+/XAsWLNDWrVu1cuXK417F7LvvvtPFF1+s2NhYxcTEKC4uTldccYUkFRgzISGhwAdCTznlFEkyfe/UL7/8ooSEBJ8dKenoqXj5v3dLTEz0ewzp6GN74sSJeueddwotytLR+2Dx4sUFtn+fPn0k2T+wXqVKFZ+dHcn/233s80I6+tzIf14UpX379nr11Ve1bds2de/eXc2aNdO///1v76mDgbocPCq+008/XQsXLtQff/yhtWvXasqUKUpLS9PgwYP1/fff+6xb2jVG8q0dx1uvVatW3jeUiuNEz6X9+/crOTlZc+fOLfBaMGrUKEm+NaZZs2YFaru/NWbWrFn6+OOP9cYbb+i8887TgQMH5PF4Cqz34osvqn379goPD1fNmjUVFxen//73v8WqDf7UzuK4/PLL9fHHH+vXX3/VokWLjltjfv31V2+DGx0drbi4OPXo0UNSwRoTHBysJk2a+CwraY0JDg5Ws2bNfJbHx8erWrVqpVZjQkJCdMcdd2jDhg1Fnja3ZcsWfffddwW2f/7tK8lFUY6dt7+321pj4uPj9c477ygrK0t9+/ZVYmKibrnlFu9XBfzVawyfSSol+e+CFdU1Z2RkFHoVrpCQkELXz38n4uGHH/Z597tRo0beD/W98cYbWr16td599119+OGHuuqqq/TII49o9erVPg/MosY40diBcKI55R9Nufnmm4t8t+fYF4WSOvvss73ntg8YMEDt2rXT8OHDtW7dOu/Ro/vvv1933nmnrrrqKt1zzz2qUaOGgoODNXHixGIdAcpf56GHHiry0uD+vNgMGzZMU6ZM0ZgxY1SzZk317du30PWSk5PVo0cPxcTE6O6771bTpk0VHh6u9evX69Zbby3xRS5KW0k+T5b/2aTp06cX+vmivLw8nXvuuZo8eXKh+fxCVtT55sde6CKf+yijVUmeq4MHD/YeEcjNzdXf/vY370Un8m8TUJSwsDCdfvrpOv3003XKKado1KhRWrBggXfHWjo5a8wVV1yhESNGFLpu/md8SssZZ5zhvbrdwIEDdeaZZ+ryyy/X5s2bva/7L7/8skaOHKmBAwfqlltuUe3atRUSEqIZM2b4XOChKKVdOy+88EJ5PB6NGDFCWVlZRV6FLzc3V+eee64OHTqkW2+9VS1btlRUVJR+++03jRw5stxqTHGvOleSGjN8+HDvZ5MK+7L0vLw8tWvXTv/6178Kzee/qeBvjZGKnndxb3dJnqtnn322fv75Z23cuFHp6enq0KGDdu/eLemvX2NokkpJ/mHmzZs3F3j3LCMjQzt37ixyR/V4rrzySu+VSqSCT4QuXbqoS5cuuu+++/Tqq69q+PDh+s9//lPkl735w32b3O/sZGdna/v27d532N3rua+ilb/MfQi+pJfHzJ9HaGiod/zjzT//CM2xc7KKjo7W1KlTNWrUKM2fP997RZc33nhDvXr10rPPPuuzfnJysrfBkoq+/fmnf8TExJzwdhVHw4YN1b17dy1fvlzjxo3zOa3Sbfny5Tp48KAWLlyos88+27t8+/btha6/e/fuApcX/emnnySpWBdROFajRo30ySefKC0tzeeoSv5pfkWdvmGRfzRp2rRphe78NG3aVIcPHz7h9s8/unnsFR79OWJanrdb+t+Obr7801ZK47GGyiN/R/73338vlb9X3NrhXu9YP/74o2rVquV9TSppjYmLi1PVqlWVm5tbrBqzadMmOY7jM25Jakx+49OrVy89+eSTuu222yQdrTFNmjTRwoULfcZyN6tS0bffn9pZHBERERo4cKBefvll9e/f36fOuW3cuFE//fSTXnzxRV155ZXe5R9//HGh6+fl5ennn3/22bkuaY3Jy8vTli1bvEfqpaMX50hOTi7V19r8o0kjR44s9KpuTZs21TfffKPevXsf93FaWjWmvG63dPS2u9/gPVlqDKfblZLevXsrLCxMs2fPLvDOyNy5c5WTk6P+/fv7/XebNGmiPn36eH+6d+8u6ejpCsd2+PkP0JJefjRfnz59FBYWpn//+98+Yz377LNKSUnR+eefL+lo4axdu7bmzJnjM/YHH3ygH374wbueJG8hs34beu3atdWzZ089/fTThRbq/NMRpaPfGbR69WqtXbvW5/evvPKKaex8w4cPV/369TVz5kzvspCQkAL3x4IFCwqc413U7e/UqZOaNm2qhx9+WIcPHy4wpvt2Fde9996rqVOnHveLH/PfPXLPPTs723s+8bFycnJ8LomanZ2tp59+WnFxcaYvaz3vvPOUm5urJ5980mf5o48+qqCgINNz5ngmTpyoatWqFXqVpCFDhmjVqlX68MMPC/wuOTlZOTk5ko4Wn5CQkAKfUSpqmxWmvG+325YtWzRnzhxdcMEFf/l3+VA2li1bVug7yPmfc/D3dLKiFLd21K1bVx07dtSLL77o89q5adMmffTRRzrvvPO8y0paY0JCQrzf9bNp06YCvz+2xuzevVtvvPGGd1lGRobmzp1rGjtfz549dcYZZ+ixxx7zXi2usNfqNWvWaNWqVT7Z/M+eHnv7/amdxXXzzTdr6tSpuvPOO4tcp7B5O46jxx9/vMiM+3XRcRw9+eSTCg0NVe/evf2eY/5j49izB/KP5rj3T0rDFVdcoWbNmhX6+dchQ4bot99+0//93/8V+N2ff/7pPWU0JiZGtWrVKnGNkcrvdrvt379fM2fOVPv27f/yTRJHkkpJ7dq1ddddd+mOO+7Q2WefrQsvvFCRkZFauXKlXnvtNfXt21cDBgwotfFefPFFPfXUU7r44ovVtGlTpaWl6f/+7/8UExPjUzBKIi4uTlOmTNH06dPVr18/XXjhhdq8ebOeeuopnX766d7PrYSGhmrmzJkaNWqUevTooWHDhnkv49q4cWPdeOON3r+ZvyP9j3/8Q0lJSQoJCSlwff0TmTVrls4880y1a9dOY8aMUZMmTbR3716tWrVKu3bt8n430eTJkzVv3jz169dPN9xwg/cS4I0aNdK3335r3i6hoaG64YYbdMstt2jx4sXq16+fLrjgAt19990aNWqUunXrpo0bN+qVV14pcG5106ZNVa1aNc2ZM0dVq1ZVVFSUOnfurMTERD3zzDPq37+/2rRpo1GjRqlevXr67bfftGzZMsXExOjdd9/1a549evTwnvddlG7duql69eoaMWKE/vGPfygoKEjz5s0r8hB7QkKCZs6cqR07duiUU07R66+/rg0bNmju3LneS7T7Y8CAAerVq5duv/127dixQx06dNBHH32kt99+WxMnTvT5gHVpiI2N1Q033FBoAbvlllv0zjvv6IILLvBe+jQ9PV0bN27UG2+8oR07dqhWrVqKjY3VpZdeqieeeEJBQUFq2rSp3nvvPb/OJy/P2926dWvvd5Rs375ds2fPVo0aNU74/VaovCZMmKCMjAxdfPHFatmypbKzs7Vy5Uq9/vrraty4sfezOSXlT+146KGH1L9/f3Xt2lWjR4/2XgI8NjbW53tj8mvM7bffrqFDhyo0NFQDBgzw68s1H3jgAS1btkydO3fWmDFj1Lp1ax06dEjr16/XJ5984v0+wTFjxujJJ5/UlVdeqXXr1qlu3bqaN29ekRfJ8cctt9yiSy+9VC+88IKuvfZaXXDBBVq4cKEuvvhinX/++dq+fbvmzJmj1q1b+7yxFhERodatW+v111/XKaecoho1aqht27Zq27ZtsWtncXXo0MHnS8sL07JlSzVt2lQ333yzfvvtN8XExOjNN98s8rMu4eHhWrx4sUaMGKHOnTvrgw8+0H//+1/985//9LmUuz9zHDFihObOnes9vXzt2rV68cUXNXDgQPXq1cvvv3k8ISEhuv322wt9jvz973/X/Pnzde2112rZsmXq3r27cnNz9eOPP2r+/Pne72eSjl5054EHHtDVV1+t0047TZ9++qn3iFpxlOft7tGjh7p27apmzZppz549mjt3rg4fPqz33nuvxKeaB1x5XUavsnj55ZedLl26OFFRUY7H43FatmzpTJ8+3eeSm47zv8sIL1iwwGf58S796LZ+/Xpn2LBhTsOGDR2Px+PUrl3bueCCC5yvvvqqwN9yX+b4eGPnX4702MuKP/nkk07Lli2d0NBQp06dOs64ceOcP/74o8CcXn/9defUU091PB6PU6NGDWf48OHOrl27fNbJyclxJkyY4MTFxTlBQUHey4EXNVfHKXjJS8dxnG3btjlXXnmlEx8f74SGhjr16tVzLrjgAueNN97wWe/bb791evTo4YSHhzv16tVz7rnnHufZZ5/16xLghV12NCUlxYmNjfVe1j0zM9O56aabnLp16zoRERFO9+7dnVWrVjk9evTwufS74xy9rHnr1q2dKlWqFLivv/76a+eSSy5xatas6Xg8HqdRo0bOkCFDnCVLlhx3rsfbfm6FXSL1iy++cLp06eJEREQ4CQkJ3sv96phL2OZfUvurr75yunbt6oSHhzuNGjVynnzyyeOOeWz+WGlpac6NN97oJCQkOKGhoU7z5s2dhx56yOdS6I5T8HKq1vH++OMP72Xgj91eaWlpzpQpU5xmzZo5YWFhTq1atZxu3bo5Dz/8sM/lj/fv3+8MGjTIiYyMdKpXr+6MHTvWe+n1Yy8Bfuz2Lq3b3ahRI2fEiBEn3A5Dhw51GjRo4ISFhTkJCQnOtdde6+zdu/eEOVReH3zwgXPVVVc5LVu2dKKjo52wsDCnWbNmzoQJEwo8dgp7fPpbe4pTOxzHcT755BOne/fuTkREhBMTE+MMGDDA+f777wusd8899zj16tVzgoODfV7r/Xku7d271xk/frzToEEDJzQ01ImPj3d69+7tzJ0712e9X375xbnwwgudyMhIp1atWs4NN9zgLF682K9LgBf2VR65ublO06ZNnaZNmzo5OTlOXl6ec//99zuNGjVyPB6Pc+qppzrvvfeeM2LECKdRo0Y+2ZUrVzqdOnVywsLCCtTP4tbOwhTnNbiwuvn99987ffr0caKjo51atWo5Y8aM8V56vbDXy23btjl9+/Z1IiMjnTp16jhTp04t8BUbhSnq9fbIkSPO9OnTncTERCc0NNRp0KCBM2XKlAL7ZY0aNXLOP//8E45TnPGaNm1a6PbKzs52Zs6c6bRp08bxeDxO9erVnU6dOjnTp093UlJSvOtlZGQ4o0ePdmJjY52qVas6Q4YMcfbt21fkJcAL208p6e0ubP+lMDfeeKPTpEkTx+PxOHFxcc7ll1/ubNu27YS5v4IgxwngJygB/GX07NlTBw4cKPQUFAAASmLkyJF64403Cj3lHAiEv/hxMAAAAAAoXTRJAAAAAOBCkwQAAAAALnwmCQAAAABcOJIEAAAAAC4n/fck5eXlaffu3apatWqJv4kbAFB8juMoLS1NCQkJf/3vyyhl1CYACIzi1qaTvknavXu3GjRoEOhpAECltXPnTtWvXz/Q06hQqE0AEFgnqk0nfZNUtWpVSdLfdv5HITH+fQv2lxt7mMY8p91/Tbmltc835Ubve9KUk6Rnm19vC3Y1DniVLZZSO9aUG9b6GVPOoyOm3HjNMuVOf8D+3UNLb+tiyt2rO025O3SPKRerFFPuWs0x5f6jYabccL1syq0ed44pJ0naZouN+ehxU25+q5G2AXfP8DOQJelR7+sw/id/m5y28xVV8bM27VOcaczt+5qYcs7XUaac9tpikqSatpjnzEOmXO/YJabc2frclGumLaZchDJNOasU2WqvJG1XoimXbBwzWrbvV2qin025RGOuSdZ2Uy7qa+MlBIz1RZIUZswZ9xF/qN/YlNulen6tn5GaoysbrDlhbTrpm6T80xhCYiJVJcbPF/roGNOY/hY8ryDbeGEx4bbxJCnYNqZCjeMZa21MtC0XarwvQpVtykUpxJQryV0YFWN7GocY74wo48tGtHHbhMh250cbP3JpHS/GWkwk8ytxWEyELWh93stjSnE6WUH526SKoTZZH6NBf9rudyfS+MJtfHhKksxlNMeUs9aKcONepPV1NML4Omp1pAS7idZt4zG+zoQb63akcYfGWtNismyvh1FRxiapJM9D210hGd8Xi46x1W3r8+lEtYmTxAEAAADA5S/RJM2aNUuNGzdWeHi4OnfurLVr1wZ6SgCASo7aBAAnrwrfJL3++uuaNGmSpk6dqvXr16tDhw5KSkrSvn37Aj01AEAlRW0CgJNbhW+S/vWvf2nMmDEaNWqUWrdurTlz5igyMlLPPfdcoetnZWUpNTXV5wcAgNJEbQKAk1uFbpKys7O1bt069enTx7ssODhYffr00apVqwrNzJgxQ7Gxsd4fLrEKAChN1CYAOPlV6CbpwIEDys3NVZ06dXyW16lTR3v27Ck0M2XKFKWkpHh/du7cWR5TBQBUEtQmADj5nXSXAPd4PPJ4rNcsBACg9FGbAOCvpUIfSapVq5ZCQkK0d6/vN9Lt3btX8fHxAZoVAKAyozYBwMmvQjdJYWFh6tSpk5Ys+d83Yefl5WnJkiXq2tX4db4AAJQAtQkATn4V/nS7SZMmacSIETrttNN0xhln6LHHHlN6erpGjRoV6KkBACopahMAnNwqfJN02WWXaf/+/brrrru0Z88edezYUYsXLy7wgVkAAMoLtQkATm5BjuM4gZ5EWUpNTT16udWULxUcE+1Xtqm2msZcmdLNlMucVsOUUzNbTJJ0wRFTbFCj1025N1dcYcrN7DHBlsu9zZQbEPKOKdda35tyb2qwKSdJXx881ZQ7sivGlItutt+UO7wjzpTb1KapKdf2t+9MueAquabcj3VamnKSNEb/Z8q107em3DqdZsqtqNbbr/VTHalWqpSSkqKYGNvj7WSVX5tOSVmhED9r0x+qZhpzz7ZEU04/BtlyybaYJMn40a7YMwu/uuCJ9PQsM+U6a60pl6DdppxVmqqacsnGx5ok7VVtUy7X+P69dZu200ZTrqO+NuUabbfVUH1li+lXY06SrO/5dLfFfk60PfEPqpZf6x9OzdU5sT+csDZV6M8kAQAAAEB5o0kCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwqRLoCZSXEOUqWLl+Zdpro2msg7G1TLlvWnYx5eLH/mzKSdKeL5qYcm9+dYUpV3/QFlNum5qZcreGPGDK3Z91uym3zWOb5x+qZspJ0pE9MaZccHy6KVctKtmUW9Gmhyn3jK425eLq7TPlPtXZplzzFbtMOUnq0+MTU+7R3BtNueQD1Uy5Z5JH+LX+n6nZUuxrprEqi58PNVHQEf+ew0eSq9oG2xNky2XaYiXaw4i2xcI82SUY1H9pst0Xu5VgyiUba8VB1TTlrLdPknIVYspVU7IpF6kMU66O9ppyjfbtN+W0wRbTJmPOVuqPCjfmbOVXDWrsMeWqxh72a/00OcVajyNJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBSJdATKC87BrWSqsT4lXnsija2wdraYtphi52qDcYBpQ+b1THl8sKjTLlqSjblwpRlyv2uBFMuZXG8Kbf7ooOm3M/fGR9rkka0mW3OWizKutiUe9Rzoym3Tp1Mudv0gCmXrGqmnGJ/seUk3ZryiCn3fux5ptzKjN6mXNDpjn+B3FRJr5nGqixyfoqRovyrTcaXUemAMXfYmIs25iQppwRZg1zj7tCfiijX3G5jTdsrW63PVpgpJ9nrfQPtLNdc69zvTTmttsX0lTH3qzFXkj19P1+avH62xULTbbm4KP9epDzFHIcjSQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgUiXQEygvr755sSJj/Lu5A6d/aBtskS2mm22xD+68xDigpJ62WI/ei0253apryuUaH6rPpFxtysVd9Ksp9/PTbUw5dbHFJGlR1sX2sEFrz/emXJJsz6d5O68x5TTHFtOlttjsjiOMA0ofKsmU+7tesg24xBab9uWtfq2fmZqlB2JtY1UaOf//xx/JxrEOGHOHjblMY06Satli2VlhplyuJ8Q2oFGObONlKNKUS1O0KWetvZJUUwfLNddU20y5mI1HTDltscW0z5jLNeaijDlJyjLmdhpzu405fx+mxXxt4kgSAAAAALjQJAEAAACAC00SAAAAALjQJAEAAACAC00SAAAAALjQJAEAAACAC00SAAAAALjQJAEAAACAC00SAAAAALjQJAEAAACAC00SAAAAALjQJAEAAACAC00SAAAAALjQJAEAAACAS5VAT6C8vKzLFapI/0I9jYN1tMWCG6ebcnmZUbYBJWmPLVZNf5hyK/7bz5Trdf5yUy7zQHVTrlvsSlOu1thlptz8dSNMOUmq5km25WTLJenDcs092OB623j32cbbpmam3Gc625STpMd1gym3Uw1Muc+v/pspt0ad/Vr/iDJM41QmnnaHFBST41cmUzVsgx2wxZRZzjnJPNe05Kq2YB1bzPo6GqZsUy7XuNuWqxBTLkthppwk1dFeUy5Bu025BtppymmfLaZcY662MWfdY/cYcyWRYszZdoP9l1W81TiSBAAAAAAuNEkAAAAA4FKhm6Rp06YpKCjI56dly5aBnhYAoBKjNgHAya/CfyapTZs2+uSTT7z/rlKlwk8ZAHCSozYBwMmtwr+qV6lSRfHx8YGeBgAAXtQmADi5VejT7SRpy5YtSkhIUJMmTTR8+HD9+uuvx10/KytLqampPj8AAJQmahMAnNwqdJPUuXNnvfDCC1q8eLFmz56t7du366yzzlJaWlqRmRkzZig2Ntb706CB7RK5AAAUhtoEACe/Ct0k9e/fX5deeqnat2+vpKQkvf/++0pOTtb8+fOLzEyZMkUpKSnen507jdfNBwCgENQmADj5VfjPJLlVq1ZNp5xyirZu3VrkOh6PRx5PIL45CwBQGVGbAODkU6GPJB3r8OHD2rZtm+rWrRvoqQAAIInaBAAnowrdJN18881asWKFduzYoZUrV+riiy9WSEiIhg0bFuipAQAqKWoTAJz8KvTpdrt27dKwYcN08OBBxcXF6cwzz9Tq1asVFxcX6KkBACopahMAnPwqdJP0n//8J9BTAADAB7UJAE5+FbpJKk2naoPC5d+HZpN7VDeNteKVfqZc3oYoU061bDFJUhfHFNuo9qbc6POfNOXG6mlTbnPTFqbchXrXlJv4iG2eCrfFJOnvnV4y5e5dd78p93ViV1PO6qka4025XOPL2z+3/cuUu7/pJFNOkp6S7TbennufKfd9SGtT7v1Rg/xaPzVbijWNVHmcGrtBVWL8e+1f07azaawjO2JMOe2yxXTYmJOkPbZY3gFbHQ2pk2vKNZDtKoWNtaNcx6umZFMuWdVMOUmqo72mnPU21jpkfMBl2mLmFzdrzriLWCIpxlxWqc7ixPy9D7OLt1qF/kwSAAAAAJQ3miQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAACXIMdxnEBPoiylpqYqNjZWKU9JMRH+ZZuO3GQaM1chptwvr7c05bTaFpMk1TLmDhhz19pin7XoZMo10zZTrlp6iimXERVuyg3Tf0w5SWqt7025nWpgynXTSlNur+qYcqfpK1NumXqZcgdV05S7TK+bcpK0Q41NuW/VzpRL0oemnL+PmczUbE2NnauUlBTFxMSYxjxZ5demISmPK8zP4rRcPU1j7nq9uSmn5baY9hhzkhRvzA22xfr3XmjKXadZplxnrTXl0hRtym3Qqaac9bVJkqop2ZTrZHzN7/DjFlPOvA910Jizst31JXPYmDtkzKUbc35KzZJi5+iEtYkjSQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgUiXQEygvLwwfooiYML8yP3/XxjRWjZa/mXJabYupsTEnSTnlmzunxXum3NO61pS7TP8x5bZFNTPlbjn4kCmXUHO3KSdJH31xkSn3bvfeptxGtTfl2mmjKbdTDUy50/SVKVdNyabch0oy5SSpqbaachfqXVNur2qbckvUx6/1c5Qhaa5prMoiUxHKVYRfmbSsqrbBkm0xHTDmdhlzkpRZvmOmybhNjWodOmzKVQux5fbF2mpMhiJNOUmqqjRTrpYO2ga0ltEt5ZyzPrbDjTmPMSeVf5dg3SfN9XP9I8VbjSNJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBSJdATKC9ROqxIhfqViWvzq2ms/a80NOXU2BbTDmNOkg4Ycw9kmmJL/3uBKTf5/Omm3AVfLTXlnCa23JqanU25z3SWKSdJirZHLd7QIFNu3SbjbZxni2mLMTfTFrsk/APjgNKRGFtuXuwwU27c0y+acovGXmzKoWhf61QF+/kkTvkq3jbYJltMW425PcacJOWU75i7lWDK/W7MHahhe+GOzMow5cKUbRtPtvEkqarSTLlqWcm2AXfbYuZasdoWyzhky4Ua99hDjfVFkhRrzEUZc7nGnL+7pMUchyNJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBSJdATKC9X//CaFB3jXyjcsQ2WY4vpSWPuamNOknoac5+Hm2JdL1tqyj24Zqopd2PnR02513WZKdda35tym3WKKSdJnTp8Zcol6HdTrpeWm3LpzW3vyUT9Pc+UW922gym3V3VMuYse/MiUkySNtcWu2vmaKffl2Lam3IcPDvRr/dRMKdY0UuWx881TpEg/a9Nq42CfG3ObjDlrLZQkW4mRDthiOw82MOW+rnmqKddAO025up7dplyaqppyIco15SQpTFm2XKbtNd/8eLPmjJvmz0xbLs04XtUSPA8jrXe/7a6XjNvGSfdz/WLu3nMkCQAAAABcaJIAAAAAwIUmCQAAAABcAtokffrppxowYIASEhIUFBSkRYsW+fzecRzdddddqlu3riIiItSnTx9t2bIlMJMFAFQK1CYAQECbpPT0dHXo0EGzZs0q9PcPPvig/v3vf2vOnDlas2aNoqKilJSUpMxM4ye7AAA4AWoTACCgV7fr37+/+vfvX+jvHMfRY489pjvuuEMXXXSRJOmll15SnTp1tGjRIg0dOrTQXFZWlrKy/ndZjdTU1NKfOADgpEVtAgBU2M8kbd++XXv27FGfPn28y2JjY9W5c2etWrWqyNyMGTMUGxvr/WnQwHZZTwAAjkVtAoDKocI2SXv27JEk1anj+50lderU8f6uMFOmTFFKSor3Z+dO23cRAABwLGoTAFQOJ92XyXo8Hnk8nkBPAwAAL2oTAPy1VNgjSfHx8ZKkvXv3+izfu3ev93cAAJQnahMAVA4VtklKTExUfHy8lixZ4l2WmpqqNWvWqGvXrgGcGQCgsqI2AUDlENDT7Q4fPqytW7d6/719+3Zt2LBBNWrUUMOGDTVx4kTde++9at68uRITE3XnnXcqISFBAwcODNykAQAnNWoTACCgTdJXX32lXr16ef89adIkSdKIESP0wgsvaPLkyUpPT9c111yj5ORknXnmmVq8eLHCw8MDNWUAwEmO2gQACHIcxwn0JMpSamqqYmNjpXYpUkiMf+H3jF8MuNpYKK+1xdTSmJOkZGOupzF3vS0WHn/IlBsV+4Ip107fmnIfKsmUe3vzMFNOkka3eNKU26pmptx4Ff4FmyfSURtMuQxFmHLJqm7KhSjHlDvz/fWmnCRdd94jppx1rqca74urrn/Nr/VTs6XY/5NSUlIUE+Pn6+9JzlubeqZIVfzcNj8aB91lzOmgMVfDOqDULMiWG2gc7wpb7MwOH5tyPbXMlGuhn0w5j7JOvFIhQpRryklSgnabch3TvzHlwj8yxaQvjLkfjLl9xtxhY85+F0ohxpz1EEx6+eRS86TYAyeuTRX2M0kAAAAAEAg0SQAAAADgQpMEAAAAAC40SQAAAADgQpMEAAAAAC40SQAAAADgYv6epOzsbO3bt095eXk+yxs2bFjiSQEAYEFtAgCUBr+bpC1btuiqq67SypUrfZY7jqOgoCDl5pbkguwAAPiP2gQAKE1+N0kjR45UlSpV9N5776lu3boKCjJ+4RsAAKWE2gQAKE1+N0kbNmzQunXr1LJly7KYDwAAfqM2AQBKk98XbmjdurUOHDhQFnMBAMCE2gQAKE1+N0kzZ87U5MmTtXz5ch08eFCpqak+PwAAlDdqEwCgNPl9ul2fPn0kSb179/ZZzodjAQCBQm0CAJQmv5ukZcuWlcU8yt6Zkjx+ZvqE28b60RZTP2OuJGeYPGnMWS8ef9gWy9xVw5SbvXWSKde309um3NV6xpSr02KfKSdJYcoy5daldzLlakfZ5rpGnU25faptyjXVNlPudV1mylU/7z5TTpIaa7sp11lrTTmP8TETlOv4F8hNlRRrGstff9na9KUkf68xYXwdlQ4acxG2WHQJLp7RzJirb8wZa9puJZhyP6i1KZft947MUQ2005SrWYIdjByFmHIZUbZ9r/AGmaac2tpisu2WSIeMud3G3F5jTpKsB+FTjDlbaSozfr8s9OjRoyzmAQCAGbUJAFCaitUkffvtt2rbtq2Cg4P17bffHnfd9u3bl8rEAAA4HmoTAKCsFKtJ6tixo/bs2aPatWurY8eOCgoKkuMUPO2C874BAOWF2gQAKCvFapK2b9+uuLg47/8DABBo1CYAQFkpVpPUqFGjQv8fAIBAoTYBAMqK6Xoumzdv1hNPPKEffvhBktSqVStNmDBBLVq0KNXJAQBQXNQmAEBp8fvLZN988021bdtW69atU4cOHdShQwetX79ebdu21ZtvvlkWcwQA4LioTQCA0uT3kaTJkydrypQpuvvuu32WT506VZMnT9agQYNKbXIAABQHtQkAUJr8PpL0+++/68orryyw/IorrtDvv/9eKpMCAMAf1CYAQGnyu0nq2bOnPvvsswLLP//8c5111lmlMikAAPxBbQIAlKZinW73zjvveP//wgsv1K233qp169apS5cukqTVq1drwYIFmj59etnMEgCAY1CbAABlpVhN0sCBAwsse+qpp/TUU0/5LBs/fryuvfbaUpkYAADHQ20CAJSVYjVJeXl5ZT0PAAD8Qm0CAJQVvz+TBAAAAAAnM9OXyf4lXeNIVR3/Mv8JMg62yxbrUt+Wa2uLSVKjHj+acr9809KU+1uHz025fapjyu2a1dyUW9a4lyn30Y8XmXI3db/XlJOkBO025TpGbTDlVqqbKbdR7Uy5EOWacjf99i9T7qN655pyJXG2Cl5woDg6pn9jyoUvMcXUf/ZCv9Y/kpqhT56zjVVpJEgK8TOTbBwrs6YtV804Xglqk7oYcx1tsfD6h0w5j7JMuT+MG3WvaptyYcZ5RirDlJOkbHlMuT8VaRuwZqYt19AWM948KcqYyzHmDhpzkpRii2XYdkv0W7otd8TP9Q8Xcz2OJAEAAACAS7GbpN27jW0hAABlhNoEACgLxW6S2rRpo1dffbUs5wIAgF+oTQCAslDsJum+++7T2LFjdemll+rQIdu5uwAAlCZqEwCgLBS7Sbruuuv07bff6uDBg2rdurXefffdspwXAAAnRG0CAJQFv65ul5iYqKVLl+rJJ5/UJZdcolatWqlKFd8/sX79+lKdIAAAx0NtAgCUNr8vAf7LL79o4cKFql69ui666KIChQgAgPJGbQIAlCa/qsj//d//6aabblKfPn303XffKS4urqzmBQBAsVCbAAClrdhNUr9+/bR27Vo9+eSTuvLKK8tyTgAAFAu1CQBQFordJOXm5urbb79V/fr1y3I+AAAUG7UJAFAWit0kffzxx2U5DwAA/EZtAgCUhWJfAhwAAAAAKgOaJAAAAABwqTTXSE3ZXU0xUf5lglZnm8a6v9Ejptw/VzxqysX3+NmUk6RfVrQ05WK77DHlaumgKfdTegtTbtj450y5z3SWKfdi936m3BTNMOUk6VbNNOUyFGHKbVQ7U+5fmmTKbVBHU65bvS9Mua90minXWt+bcpLUUV+bcuHbjQN+ZIu9nzXIr/VTM6RY21CVx0BJHj8zmcaxcow5655CY2NOktraYqFtU025BrE7TbmaxprmkW3/4k9FmnIHVcuUq6o0U06SamuvKZejENuA1sepcbi/jJLs6RtfM/am23I7bDH5+6zPKOZ6HEkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAAJcqgZ5AeYmdmyKFxviViV/ws2msefq7Kdeqx3pT7ocv/mbKSVKNM38z5Q7tSDDlkptWM+XCwrNNuc06xZQbrDdMuRF60ZTb9U1zU06Svu7woSl3u+435V4yPr53qoEplyWPKTdup+2+0Oe22P5h0bagpH2qbQvm7DfmbDG/K0alqTAlcLqkSD8z1oea9X7PNObsTwmp8RFTLKHmblOujvaZcjV1wJSrolxTLkthptxB1TTlIpVhyklSonaYctZto3RbzJyzsr4u1jDmbKW3RBKNt7Hmr7bc3iz/1j9czPU4kgQAAAAALjRJAAAAAOAS0Cbp008/1YABA5SQkKCgoCAtWrTI5/cjR45UUFCQz0+/fv0CM1kAQKVAbQIABLRJSk9PV4cOHTRr1qwi1+nXr59+//13789rr71WjjMEAFQ21CYAQEA/Vtu/f3/179//uOt4PB7Fx8eX04wAAJUdtQkAUOE/k7R8+XLVrl1bLVq00Lhx43Tw4MHjrp+VlaXU1FSfHwAAShO1CQBObhW6SerXr59eeuklLVmyRDNnztSKFSvUv39/5eYWfXnIGTNmKDY21vvToEEArn0IADhpUZsA4ORXob/FYujQod7/b9eundq3b6+mTZtq+fLl6t27d6GZKVOmaNKkSd5/p6amUowAAKWG2gQAJ78KfSTpWE2aNFGtWrW0devWItfxeDyKiYnx+QEAoKxQmwDg5POXapJ27dqlgwcPqm7duoGeCgAAkqhNAHAyCujpdocPH/Z552379u3asGGDatSooRo1amj69OkaNGiQ4uPjtW3bNk2ePFnNmjVTUlJSAGcNADiZUZsAAAFtkr766iv16tXL++/887VHjBih2bNn69tvv9WLL76o5ORkJSQkqG/fvrrnnnvk8XgCNWUAwEmO2gQACGiT1LNnTzmOU+TvP/zww3KcDQAA1CYAQAW/ul2petv/SBUVfTnX48mS7d3Enx9vY8rpR1tMkgZ3f8OUm7vnBlNuUFPbeDtDbFeByjU+xOekjDXlMp+pYcrFXr/HlJOkPxVpyr2v80w5j7JNuU/Ux5RLVjVT7qkG19nGG2Ybr7eWmHKSlK0wU+66jrNMuSlzHjDlummlX+tnpmZLesE0VqWR8/9//BFuHMta8Q+X83iSVMVWf0OMddsq21jv/1SIKWfdvwjx+0F2VDUlm3KSlGO8jWHGGqNMW8z8OK1ZzjnrxTCbG3OSlG7MHbLFYnYbc/v8Wz/1iKRi7I7+pS7cAAAAAABljSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADAhSYJAAAAAFxokgAAAADApUqgJ1Bu+sjvW9tU20xDnaf/mnK3Rj9hyinHFpOkNFW1BT+xxXZ0TzTl3tBgUy5R2025zE01TLm+N71tyn305kWmnCQ9En6HKTf3/L+bcmNeftmU+/iKM025zWphyrXQZlPOqqYOmrNP6TpTbpL+Zcr9ZNymA/WWX+tn6IhpnErlZ0nhfmYyjWP5O06+w8ZcSfYwqtgmuzu6rimXGxtiyoUpyzZeOe9+1dFeUy5Xtu1SEuYxrY/v2sZcTVvMibLlgkqwr1fubE8LGR+m8ntXL0PSGydejSNJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBCkwQAAAAALjRJAAAAAOBSJdATKDef+B/ZocamoW6d/oQpp3hbzJyT9G76AFtwqC32atblplzKHbYbuX9PQ1Ouw7zVpty3amfK3TToXlNOkjpqgymXpmhTbvYVI0y5140PmhW/9TTl+tb70JQ7RZtNuUj9acpJUpY8ptxHay4y5Wqc9pspN+zat/1aPzVbuto0UiXyvaQwPzMHjGOFG3OZxlxJ9jAO22KZmTVMuV/ibbnyFlor1ZTz1Mwy5ayvTZKUrGqm3F7VNuWqJqaZcrlVQky5AyE1Tbls4zYNUa4pFybbfS9JVYxjRijDlKuRY3yx2e3n+sW8WRxJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAACXKoGeQLkZIinMv8gvj7c0DRV8bbopl3c40pTT8iBbTtLhDXG24Ce2WMgdubbgmbaYom2xb17pYso1Gf6dKbdVTU05SdqpBqbcpzrLlHtIk025g6ppylltVgtTrqm2mXLfq7UpJ0mNtd2Uu7Fzkik3VdNNudQ5of6tn+pIL+WYxqo0fpb/lXiPcSxrxbfehcbXX0lSpjFnnWuyMVfOjsTHmHJ7q9Ux5faF1DblJGmHEk25qjpsyqV5qppyHmWbchmy7bPlKsSUq6o0U66mDphyklQ9N9mUi/n5iG3ADbaYNvm5flbxVuNIEgAAAAC40CQBAAAAgAtNEgAAAAC40CQBAAAAgAtNEgAAAAC40CQBAAAAgAtNEgAAAAC40CQBAAAAgAtNEgAAAAC40CQBAAAAgAtNEgAAAAC40CQBAAAAgAtNEgAAAAC4VAn0BMrN9Eypaph/mU/CTUPlrY4y5fSyLaZkY06SrjDmWtpiVUPSTLlDmbbxSrRtDH5e18aUS+5YzTzmocX1TLm/nf+5KfeGBplyl+tVU+60el+ZcjvU2JT7UEmmnEdZppwkDdXrptxuJZhy/9IkUy7m6yP+BQ6bhqlcfpX/b1fmGMey5qx7CvWNOUmKNubijTlrjbFuG+t9kWyLHdpT05TbWa+BbUBJEcow5UKUa8ply899vP+vmnGjWucZYrzzq8q2/1S1BC/EMVv8fM3PZyvbkm23RNrg5/rFvAs4kgQAAAAALjRJAAAAAOBCkwQAAAAALgFtkmbMmKHTTz9dVatWVe3atTVw4EBt3rzZZ53MzEyNHz9eNWvWVHR0tAYNGqS9e/cGaMYAgJMZdQkAIAW4SVqxYoXGjx+v1atX6+OPP9aRI0fUt29fpaene9e58cYb9e6772rBggVasWKFdu/erUsuuSSAswYAnKyoSwAAKcBXt1u8eLHPv1944QXVrl1b69at09lnn62UlBQ9++yzevXVV3XOOedIkp5//nm1atVKq1evVpcuXQr8zaysLGVl/e8qU6mpqWV7IwAAJ42yqEsStQkA/moq1GeSUlJSJEk1atSQJK1bt05HjhxRnz59vOu0bNlSDRs21KpVqwr9GzNmzFBsbKz3p0ED++UrAQCVW2nUJYnaBAB/NRWmScrLy9PEiRPVvXt3tW3bVpK0Z88ehYWFqVq1aj7r1qlTR3v27Cn070yZMkUpKSnen507d5b11AEAJ6HSqksStQkA/moqzJfJjh8/Xps2bdLnn1u/Seooj8cjj8dTSrMCAFRWpVWXJGoTAPzVVIgjSddff73ee+89LVu2TPXr/+8ruuPj45Wdna3k5GSf9ffu3av4eOvXagMAcHzUJQCo3ALaJDmOo+uvv15vvfWWli5dqsTERJ/fd+rUSaGhoVqyZIl32ebNm/Xrr7+qa9eu5T1dAMBJjroEAJACfLrd+PHj9eqrr+rtt99W1apVvedzx8bGKiIiQrGxsRo9erQmTZqkGjVqKCYmRhMmTFDXrl2LvIIQAABW1CUAgBTgJmn27NmSpJ49e/osf/755zVy5EhJ0qOPPqrg4GANGjRIWVlZSkpK0lNPPVXOMwUAVAbUJQCAJAU5juMEehJlKTU1VbGxsUpIWa/gmGi/srumNLcN+owtprbGXE9jTlKrqetNuR+++JspF91xvynXOGqHKbfpi9NNOW2yxZRpi7W94UvjgFKaqppyvzzb0pQbNPplU663PjHlnta1plwzbTXldsp2aeYGsl+t7I19fzflbq09zZSb+Zot9/GwM/1aPz01RxfHrlZKSopiYmJMY56s8muTlCLJ321j/Y6lI8ZcTVussXE4SbIelDvNmGtmzPm3W1Fy4cZcvG1Xr35T2+uoJJ2izaZcM20z5ZoaX/OrK9mUC1O2KVdVaaactca0zvrelJOkqNV5tuBS44Dv22K7vvJv/TRJraUT1qYKceEGAAAAAKgoaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwKVKoCdQXna/3lSKjPEvtMk4mHWrtjXmLjDmJP3w9N9MueCB6aZcRNSfplyWwky5Rt1/NOV2NmtgyuXtijLlNn13uiknST3aLDblLhv9uim3V7VNudc11JT75rsuplzHNl+bctFKM+UyFGnKSdKC2rYn8WWy3YeLh/Uw5Tpqg1/rp8kxjVO5fC0p2s/MIeNYocZcI1vsQKJxPEnJxlymMZdjzIUbc9WMuegjplhs/EFTrqrx9VCSPMo25UKUa8r9WYLXYAvr7QtTlimXqxBbrootJ0mqkmfLWZ9Pu22xL/xcP6OY63EkCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcaJIAAAAAwIUmCQAAAABcqgR6AuXmNvnfEh4wjnWzMbfVmJtmzElS2xJkDfavaGjLbbLlGo3/0ZS7tc5MU+6zOmeZcmsOdjblJGnFkn6mXOPe2025d3MvNOXOCvnUlNNhW+w0rTPlqivZlDtDa0w5Sbo2d44pd2PIo6ZcTtAjppy/j5g/TaNUNt9LivAzk2ocy99xSuhwfXt2V6gxZxyvVjnnqmWaYvXr7TTlamuvKVdH+0y5kowZqQzzmBZ/KrJcxytvf4RUM2djEvfbggnmIU383X0u7rOPI0kAAAAA4EKTBAAAAAAuNEkAAAAA4EKTBAAAAAAuNEkAAAAA4EKTBAAAAAAuNEkAAAAA4EKTBAAAAAAuNEkAAAAA4EKTBAAAAAAuNEkAAAAA4EKTBAAAAAAuNEkAAAAA4FIl0BMoNw9IivQzc61xrB+NufeO2HIdQ40DSmpri+VdEGULXmCLqaMttvtggin3RPgEU65j1AZT7qGat5hykvRV79NMuTraZ8qlJVc15W6rOdOU+6lzC1PuPv3TlPtafzPlXtXlppwkHTqtnil35/UPm3LOxkdMucxE/9ZPTZVusj0FK5HdksL9zBhrhay1IsKY22HMSdrR3JarbxyvljEXb4sFV8k15WrqoCmXaLwvahvrhCRVVZopF6kM85gWOQop1/GqyHbfWyWrmjnrScg25eITU2wD1rDFjuz2b/2cYq7HkSQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKFJAgAAAACXKoGeQFlzHOfo//yZaggbBz1izFmDuaHWAaUsYy7XmMs05jJsMSfNcL9LcrKzTbmc3HRTLlO28SQpW3+aclnGO8O6TdNDbQ+aXB025fIUYsqlGZ/4JbkPlWvbpsa7Xqm2TapMP6eZlnb0v97XYXj9b5tYXoRzjKNaX7iNDzTjc1eS5BifE9ZNY62F5tpkqxW5EbbcEeN9mG0u2vYaE2y+M2xyjbUi1Pian2Hc10s3Pn9zzc97KdJYDyONzwvrVP19xOSvf6LaFOSc5NVr165datCgQaCnAQCV1s6dO1W/fv1AT6NCoTYBQGCdqDad9E1SXl6edu/erapVqyooKMjnd6mpqWrQoIF27typmJiYAM2w4mG7FI1tUzi2S9Eq87ZxHEdpaWlKSEhQcDBnd7tRm/zHdika26ZwbJfCVfbtUtzadNKfbhccHHzCdzBjYmIq5YPkRNguRWPbFI7tUrTKum1iY2MDPYUKidpkx3YpGtumcGyXwlXm7VKc2sRbewAAAADgQpMEAAAAAC6VuknyeDyaOnWqPB5PoKdSobBdisa2KRzbpWhsG/iLx0zh2C5FY9sUju1SOLZL8Zz0F24AAAAAAH9U6iNJAAAAAHAsmiQAAAAAcKFJAgAAAAAXmiQAAAAAcKm0TdKsWbPUuHFjhYeHq3Pnzlq7dm2gpxRw06ZNU1BQkM9Py5YtAz2tgPj00081YMAAJSQkKCgoSIsWLfL5veM4uuuuu1S3bl1FRESoT58+2rJlS2AmW45OtF1GjhxZ4DHUr1+/wEy2HM2YMUOnn366qlatqtq1a2vgwIHavHmzzzqZmZkaP368atasqejoaA0aNEh79+4N0IxRUVGbCqI2HUVdKhq1qXDUppKplE3S66+/rkmTJmnq1Klav369OnTooKSkJO3bty/QUwu4Nm3a6Pfff/f+fP7554GeUkCkp6erQ4cOmjVrVqG/f/DBB/Xvf/9bc+bM0Zo1axQVFaWkpCRlZmaW80zL14m2iyT169fP5zH02muvleMMA2PFihUaP368Vq9erY8//lhHjhxR3759lZ6e7l3nxhtv1LvvvqsFCxZoxYoV2r17ty655JIAzhoVDbWpaNQm6tLxUJsKR20qIacSOuOMM5zx48d7/52bm+skJCQ4M2bMCOCsAm/q1KlOhw4dAj2NCkeS89Zbb3n/nZeX58THxzsPPfSQd1lycrLj8Xic1157LQAzDIxjt4vjOM6IESOciy66KCDzqUj27dvnSHJWrFjhOM7Rx0doaKizYMEC7zo//PCDI8lZtWpVoKaJCobaVDhqU0HUpaJRm4pGbfJPpTuSlJ2drXXr1qlPnz7eZcHBwerTp49WrVoVwJlVDFu2bFFCQoKaNGmi4cOH69dffw30lCqc7du3a8+ePT6PodjYWHXu3JnHkKTly5erdu3aatGihcaNG6eDBw8GekrlLiUlRZJUo0YNSdK6det05MgRn8dMy5Yt1bBhQx4zkERtOhFq0/FRl06M2kRt8lela5IOHDig3Nxc1alTx2d5nTp1tGfPngDNqmLo3LmzXnjhBS1evFizZ8/W9u3bddZZZyktLS3QU6tQ8h8nPIYK6tevn1566SUtWbJEM2fO1IoVK9S/f3/l5uYGemrlJi8vTxMnTlT37t3Vtm1bSUcfM2FhYapWrZrPujxmkI/aVDRq04lRl46P2kRtsqgS6Amg4ujfv7/3/9u3b6/OnTurUaNGmj9/vkaPHh3AmeGvYujQod7/b9eundq3b6+mTZtq+fLl6t27dwBnVn7Gjx+vTZs2VcrPTABlgdqEkqI2UZssKt2RpFq1aikkJKTAlTv27t2r+Pj4AM2qYqpWrZpOOeUUbd26NdBTqVDyHyc8hk6sSZMmqlWrVqV5DF1//fV67733tGzZMtWvX9+7PD4+XtnZ2UpOTvZZn8cM8lGbio/aVBB1yT/UpqOoTcdX6ZqksLAwderUSUuWLPEuy8vL05IlS9S1a9cAzqziOXz4sLZt26a6desGeioVSmJiouLj430eQ6mpqVqzZg2PoWPs2rVLBw8ePOkfQ47j6Prrr9dbb72lpUuXKjEx0ef3nTp1UmhoqM9jZvPmzfr11195zEAStckf1KaCqEv+oTYdRW06vkp5ut2kSZM0YsQInXbaaTrjjDP02GOPKT09XaNGjQr01ALq5ptv1oABA9SoUSPt3r1bU6dOVUhIiIYNGxboqZW7w4cP+7zDtH37dm3YsEE1atRQw4YNNXHiRN17771q3ry5EhMTdeeddyohIUEDBw4M3KTLwfG2S40aNTR9+nQNGjRI8fHx2rZtmyZPnqxmzZopKSkpgLMue+PHj9err76qt99+W1WrVvWeyx0bG6uIiAjFxsZq9OjRmjRpkmrUqKGYmBhNmDBBXbt2VZcuXQI8e1QU1KbCUZuOoi4VjdpUOGpTCQX68nqB8sQTTzgNGzZ0wsLCnDPOOMNZvXp1oKcUcJdddplTt25dJywszKlXr55z2WWXOVu3bg30tAJi2bJljqQCPyNGjHAc5+jlVu+8806nTp06jsfjcXr37u1s3rw5sJMuB8fbLhkZGU7fvn2duLg4JzQ01GnUqJEzZswYZ8+ePYGedpkrbJtIcp5//nnvOn/++adz3XXXOdWrV3ciIyOdiy++2Pn9998DN2lUSNSmgqhNR1GXikZtKhy1qWSCHMdxyr4VAwAAAIC/hkr3mSQAAAAAOB6aJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCAAAAABeaJAAAAABwoUkCKqDGjRvrscceO+46QUFBWrRoUbnMBwAAahMqE5okoIzk5uaqW7duuuSSS3yWp6SkqEGDBrr99ttL9Pd///139e/fv0R/AwBQuVCbgOKhSQLKSEhIiF544QUtXrxYr7zyinf5hAkTVKNGDU2dOrVEfz8+Pl4ej6ek0wQAVCLUJqB4aJKAMnTKKafogQce0IQJE/T777/r7bff1n/+8x+99NJLCgsLO242LS1Nw4YNU1RUlOrVq6dZs2b5/N59SsOOHTsUFBSkhQsXqlevXoqMjFSHDh20atWqsrppAIC/KGoTcGI0SUAZmzBhgjp06KC///3vuuaaa3TXXXepQ4cOJ8w99NBD6tChg77++mvddtttuuGGG/Txxx8fN3P77bfr5ptv1oYNG3TKKado2LBhysnJKa2bAgA4SVCbgOMLchzHCfQkgJPdjz/+qFatWqldu3Zav369qlSpctz1GzdurFatWumDDz7wLhs6dKhSU1P1/vvvSzr6bt1bb72lgQMHaseOHUpMTNQzzzyj0aNHS5K+//57tWnTRj/88INatmxZdjcOAPCXRG0CisaRJKAcPPfcc4qMjNT27du1a9euYmW6du1a4N8//PDDcTPt27f3/n/dunUlSfv27fNztgCAyoDaBBSNJgkoYytXrtSjjz6q9957T2eccYZGjx6tsjqAGxoa6v3/oKAgSVJeXl6ZjAUA+OuiNgHHR5MElKGMjAyNHDlS48aNU69evfTss89q7dq1mjNnzgmzq1evLvDvVq1aldVUAQCVBLUJODGaJKAMTZkyRY7j6IEHHpB09Hzuhx9+WJMnT9aOHTuOm/3iiy/04IMP6qefftKsWbO0YMEC3XDDDeUwawDAyYzaBJwYTRJQRlasWKFZs2bp+eefV2RkpHf52LFj1a1btxOe2nDTTTfpq6++0qmnnqp7771X//rXv5SUlFQeUwcAnKSoTUDxcHU7AAAAAHDhSBIAAAAAuNAkAQAAAIALTRIAAAAAuNAkAQAAAIALTRIAAAAAuNAkAQAAAIALTRIAAAAAuNAkAQAAAIALTRIAAAAAuNAkAQAAAIALTRIAAAAAuPw/UaSKLE570JsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 9\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(rate_maps[n], cmap='jet')\n",
    "axs[0].set_title(f'Un-smoothed Rate Map for Neuron {n}')\n",
    "axs[0].set_xlabel('X bin')\n",
    "axs[0].set_ylabel('Y bin')\n",
    "\n",
    "axs[1].imshow(rate_maps_smooth[n], cmap='jet')\n",
    "axs[1].set_title(f'Smoothed Rate Map for Neuron {n}')\n",
    "axs[1].set_xlabel('X bin')\n",
    "axs[1].set_ylabel('Y bin')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: we can plot 100 rate maps at once here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48da58",
   "metadata": {},
   "source": [
    "### **4. Polar maps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f66df",
   "metadata": {},
   "source": [
    "Comparable to rate maps, the **polar maps** show how a neuron fires when it is tuned to a specific angle (the head direction tuning).\n",
    "\n",
    "**Note**: In this notebook, we have used the term _head direction_ and _theta_ interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c591c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_polar_maps(latent_activity: np.array, head_directions: np.array, n_samples_thet: int):\n",
    "    \"\"\"\n",
    "    Calculate the polar data for the given latent data.\n",
    "\n",
    "    Args:\n",
    "    latent_activity (np.array): (n_samples, n_units) The latent data, neurons' activities.\n",
    "    head_directions (np.array): (n_samples,) The theta angles corresponding to each sample in radians.\n",
    "    n_samples_thet (int): Number of bins in the theta direction (default is 60, i.e. 6 degrees).\n",
    "\n",
    "    Returns:\n",
    "    polar_maps (np.array): (n_units, n_samples_thet) Array of polar maps, one for each unit.\n",
    "    pm_std (np.array): (n_units, n_samples_thet) Array of standard deviations for polar maps.\n",
    "    \"\"\"\n",
    "    assert latent_activity.shape[:-1] == head_directions.shape[:-1]\n",
    "\n",
    "    # obtain the theta intervals for each directional bin\n",
    "    bins_thet = np.linapce(-np.pi, np.pi, n_samples_thet+1)\n",
    "\n",
    "    # check if there is at least one data point for each directional bin\n",
    "    indices = np.digitize(head_directions, bins_thet)\n",
    "    is_data_available = [np.any(indices==idx) for idx in range(1, n_samples_thet+1)]\n",
    "    if not np.all(is_data_available):\n",
    "        raise ValueError(\"There is at least one directional bin without data. Check:\", is_data_available)\n",
    "\n",
    "    # the latent activity is projected in polar space by taking the\n",
    "    # average activity for each directional bin\n",
    "    polar_maps = [\n",
    "        np.mean(latent_activity[indices==idx], axis=0)\\\n",
    "        for idx in range(1, n_samples_thet+1)\n",
    "    ]\n",
    "    # standard deviation for each directional bin\n",
    "    pm_std = [\n",
    "        np.std(latent_activity[indices==idx], axis=0)\\\n",
    "        for idx in range(1, n_samples_thet+1)\n",
    "    ]\n",
    "\n",
    "    return np.stack(polar_maps, axis=1), np.stack(pm_std, axis=1)\\\n",
    "\n",
    "def compute_polar_maps_smooth(latent_activity: np.array, head_directions: np.array, n_samples_thet=60, sigma=2):\n",
    "    # circular convolution here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39328beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_thet = 60\n",
    "bins_thet = np.linapce(-np.pi, np.pi, n_samples_thet+1)\n",
    "\n",
    "polar_maps, pm_stds = compute_polar_maps(hidden_states, head_directions, n_samples_thet=n_samples_thet)\n",
    "\n",
    "polar_maps_smooth = compute_polar_maps_smooth(hidden_states, head_directions, n_samples_thet=n_samples_thet, sigma=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2168a2",
   "metadata": {},
   "source": [
    "Let's plot the polar map of the same neuron. Note that we will need to use the polar projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c406e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), polar=True)\n",
    "\n",
    "axs[0].plot(bins_thet[:-1], polar_maps[n])\n",
    "axs[0].set_title(f'Un-smoothed Polar Map for Neuron {n}')\n",
    "axs[0].set_xlabel('Theta (radians)')\n",
    "axs[0].set_ylabel('Average Activity')\n",
    "\n",
    "axs[1].plot(bins_thet[:-1], polar_maps_smooth[n])\n",
    "axs[1].set_title(f'Smoothed Polar Map for Neuron {n}')\n",
    "axs[1].set_xlabel('Theta (radians)')\n",
    "axs[1].set_ylabel('Average Activity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447599c",
   "metadata": {},
   "source": [
    "### **5. Spatial Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574fcce",
   "metadata": {},
   "source": [
    "In this part we will examine some commonly used metrics used to classify (the quality of) spatial cells, both in computational modelling and in _in vivo_ experiments.\n",
    "\n",
    "These metrics often include:\n",
    "\n",
    "* Spatial Information\n",
    "\n",
    "* Rate Map stablity\n",
    "\n",
    "* Kullbeck-Leibler Divergence\n",
    "\n",
    "* Resulted Vector Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35920f5c",
   "metadata": {},
   "source": [
    "**Spatial Information (SI)**\n",
    "The SI measures how much information (in bits) a cell's firing conveys about the animal's position per spike.\n",
    "\n",
    "Given:\n",
    "- `N`: number of spatial bins  \n",
    "- `p_i`: probability of being in bin *i*  \n",
    "- `λ_i`: mean firing rate in bin *i*  \n",
    "- `λ`: overall mean firing rate  \n",
    "\n",
    "Where\n",
    "$$ p_i = \\frac{\\text{time in bin } i}{\\text{total time}} $$\n",
    "$$ \\lambda = \\sum_{i=1}^{N} p_i \\lambda_i $$\n",
    "\n",
    "The spatial information content is:\n",
    "$$\n",
    "I = \\sum_{i=1}^{N} p_i \\frac{\\lambda_i}{\\lambda} \\log_2 \\left( \\frac{\\lambda_i}{\\lambda} \\right)\n",
    "$$\n",
    "\n",
    "In our modelling, the RNN processed with a sigmoidal function such that the hidden states are between 0 and 1 rather than a real firing rate. We can treat this as activity regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spatial_info(rate, occ):\n",
    "    \"\"\"\n",
    "    Computes the spatial information of the rate maps.\n",
    "    \n",
    "    Args:\n",
    "        rate_maps (np.array): The rate maps of shape (n_neurons, n_bins, n_bins).\n",
    "        occupancy (np.array): The occupancy map of shape (n_bins, n_bins).\n",
    "        \n",
    "    Returns:\n",
    "        spatial_info (np.array): The spatial information for each cell.\n",
    "    \"\"\"\n",
    "\n",
    "    # copied from metrics.py - to be modified for readability\n",
    "    no_occ = np.logical_or(occ == 0, np.isnan(occ))\n",
    "    _rate = rate[~no_occ]\n",
    "    _occ = occ[~no_occ]\n",
    "    # turn occ in a probability\n",
    "    p_occ = _occ / np.nansum(_occ)\n",
    "    _rate_sum = np.nanmean(_rate)\n",
    "    mask = _rate > 0\n",
    "    SI = np.nansum(\n",
    "        p_occ[mask] * (_rate[mask] / _rate_sum) * np.log2(_rate[mask] / _rate_sum)\n",
    "    )\n",
    "    SI /= _rate_sum\n",
    "    return SI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffdc93",
   "metadata": {},
   "source": [
    "**Stability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374465e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41422429",
   "metadata": {},
   "source": [
    "**Kullbeck-Leibler Divergence**\n",
    "\n",
    "The KL divergence is a distance metric that measures the difference between two distributions.\n",
    "\n",
    "In spatial cell analysis, it is used to quantify how head-directed a cell is. The polar map (which itself is a distribution on polar coordinate) is compared to a uniform distribution.\n",
    "\n",
    "KL is a functional of two distributions P and Q:\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P \\,\\|\\, Q) = \\sum_{i=1}^{N} P_i \\log_2 \\frac{P_i}{Q_i}\n",
    "$$\n",
    "Note that this metric tends to 0 if P and Q have the same distribution, and large if they are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl_divergence(p, q, eps=1e-10):\n",
    "    '''\n",
    "    Computes the Kullback-Leibler divergence between two probability distributions.\n",
    "    '''\n",
    "    # modified to ensure readability\n",
    "    p = np.clip(p, eps, None)\n",
    "    q = np.clip(q, eps, None)\n",
    "    return np.sum(p * np.log(p / q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014dd41f",
   "metadata": {},
   "source": [
    "### **6. Comparison with Real Neurons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e5dca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cns_tuts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
