{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124450f7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Modelling hippocampal neurons of animals navigating in VR with Recurrent Neural Networks\n",
    "\n",
    "##### *Tutorial, COS 2025*\n",
    "### *Part 4: Extracting Neural Representations from an RNN*\n",
    "##### made by: Daniel Liu, Marco Abrate, UCL\n",
    "---\n",
    "In this notebook, we will write code to extract representations from the **RNN hidden states**. These includes:\n",
    "\n",
    "* Rate maps\n",
    "\n",
    "* Polar maps\n",
    "\n",
    "* Quantitative metrics\n",
    "\n",
    "* Comparison with _in vivo_ data\n",
    "\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "* Completed Notebook 2\n",
    "\n",
    "Before starting this notebook, make sure you have:\n",
    "\n",
    "* All frames, processed into embeddings in ```.npy``` file, from the Autoencoder we trained in the last tutorial.\n",
    "\n",
    "* Trajectory file, including speed and rotational velocity at each discritised time step.\n",
    "\n",
    "* The accompanying `utils.py` helper functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00121d04",
   "metadata": {},
   "source": [
    "### **0. Install and import dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    \n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8a4ca",
   "metadata": {},
   "source": [
    "### **1. Loading test data and the trained RNN**\n",
    "\n",
    "In the first step, we will define the RNN in Part 3 of this tutorial and load the trained weights. We will also need the test embeddings and auxiliary variables, with which we will use to compute the rate maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, do not modify it.\n",
    "\n",
    "def create_multiple_subsampling(data, stride, is_velocity=False):\n",
    "    new_length = data.shape[0]//stride if not is_velocity else data.shape[0]//stride-1\n",
    "    data_multisubs = np.zeros(\n",
    "        (stride, new_length, data.shape[1]),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    for start_idx in range(stride):\n",
    "        if is_velocity:\n",
    "            if start_idx < stride-1:\n",
    "                data_multisubs[start_idx] = data[start_idx+1:start_idx-stride+1].reshape(\n",
    "                    new_length, stride, -1\n",
    "                ).sum(axis=1)\n",
    "            else:\n",
    "                data_multisubs[start_idx] = data[start_idx+1:].reshape(\n",
    "                    new_length, stride, -1\n",
    "                ).sum(axis=1)\n",
    "        else:\n",
    "            data_multisubs[start_idx] = data[start_idx::stride]\n",
    "    return data_multisubs\n",
    "\n",
    "class RNNCell(torch.nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, input_bias, hidden_bias):\n",
    "        super(RNNCell, self).__init__()\n",
    "\n",
    "        self.in2hidden = torch.nn.Linear(n_inputs, n_hidden, bias=input_bias)\n",
    "        self.hidden2hidden = torch.nn.Linear(n_hidden, n_hidden, bias=hidden_bias)\n",
    "\n",
    "        self.activation_fn = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        igates = self.in2hidden(x)\n",
    "        hgates = self.hidden2hidden(hidden)\n",
    "        return self.activation_fn(igates + hgates)\n",
    "\n",
    "\n",
    "class RNNModule(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, device, n_inputs, n_hidden,\n",
    "        input_bias, hidden_bias\n",
    "    ):\n",
    "        super(RNNModule, self).__init__()\n",
    "\n",
    "        self.rnn_cell = RNNCell(n_inputs, n_hidden, input_bias, hidden_bias)\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: [BATCH SIZE, TIME, N_FEATURES]\n",
    "        # hidden: [BATCH SIZE, N_HIDDEN]\n",
    "        \n",
    "        output = torch.zeros(x.shape[0], x.shape[1], self.n_hidden).to(self.device)\n",
    "\n",
    "        if hidden is None:\n",
    "            h_out = torch.zeros(x.shape[0], self.n_hidden) # initialize hidden state\n",
    "            h_out = h_out.to(self.device)\n",
    "        else:\n",
    "            h_out = hidden\n",
    "\n",
    "        window_size = x.shape[1]\n",
    "\n",
    "        # loop over time\n",
    "        for t in range(window_size):\n",
    "            x_t = x[:,t,...]\n",
    "            h_out = self.rnn_cell(x_t, h_out)\n",
    "            output[:,t,...] = h_out\n",
    "\n",
    "        # return all outputs, and the last hidden state\n",
    "        return output, h_out\n",
    "\n",
    "class PredictiveRNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        device, n_inputs, n_hidden, n_outputs, bias=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = RNNModule(\n",
    "            device, n_inputs, n_hidden,\n",
    "            input_bias=bias, hidden_bias=bias\n",
    "        )\n",
    "\n",
    "        self.linear_layer = torch.nn.Linear(n_hidden, n_outputs, bias=bias)\n",
    "\n",
    "    def inputs2hidden(self, inputs, hidden):\n",
    "        \"\"\" Encodes the input tensor into a latent representation.\n",
    "\n",
    "        Args:\n",
    "            x: [BATCH SIZE, TIME, CHANNELS, HEIGHT, WIDTH]\n",
    "        \"\"\"\n",
    "        \n",
    "        if hidden is not None:\n",
    "            return self.rnn(inputs, hidden[None, ...])[0]\n",
    "        else:\n",
    "            return self.rnn(inputs)[0]\n",
    "\n",
    "    def hidden2outputs(self, hidden):\n",
    "        return self.linear_layer(hidden)\n",
    "    \n",
    "    def forward(self, inputs, hidden=None):\n",
    "        hidden_new = self.inputs2hidden(inputs, hidden)\n",
    "\n",
    "        output = self.hidden2outputs(hidden_new)\n",
    "\n",
    "        return output, hidden_new[:,-1,:]\n",
    "\n",
    "class SensoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, embs, vels, rot_vels, pos, hds, tsteps=9):\n",
    "        '''\n",
    "        The initialisation function for the SensoryDataset class.\n",
    "        At initialisation, all embeddings are converted to tensors.\n",
    "        Args:\n",
    "            embs: The visual embeddings of shape (N, T, D)\n",
    "            vels: The speed signals of shape (N, T-1, 1)\n",
    "            rot_vels: The rotational velocities of shape (N, T-1, 1)\n",
    "            pos: The positions of shape (N, T, 2)\n",
    "            hds: The headings of shape (N, T, 1)\n",
    "            tsteps: The number of time steps for each batch.\n",
    "                By default, this is set to 9 i.e. we use the sensory input from steps 1 to 9          \n",
    "        '''\n",
    "        self.embs = torch.from_numpy(embs)\n",
    "        self.vels = torch.from_numpy(vels)\n",
    "        self.rot_vels = torch.from_numpy(rot_vels)\n",
    "        self.pos = torch.from_numpy(pos)\n",
    "        self.hds = torch.from_numpy(hds)\n",
    "        \n",
    "        self.tsteps = tsteps\n",
    "    \n",
    "    def __len__(self):\n",
    "        # COMPLETE THE CODE HERE: how many samples are in the dataset?\n",
    "        return self.embs.shape[1] // self.tsteps - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        This function returns a batch of sensory inputs and the corresponding future sensory inputs.\n",
    "        Args:\n",
    "            idx: The index of the sample to return. idx will be automatically generated by the DataLoader.\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        vels, rot_vels, pos, hds, embs_labels = [], [], [], [], []\n",
    "\n",
    "        start_idx, end_idx = idx*self.tsteps, (idx + 1)*self.tsteps\n",
    "\n",
    "        embs = self.embs[:, start_idx:end_idx]\n",
    "\n",
    "        vels = self.vels[:, start_idx:end_idx]\n",
    "        rot_vels = self.rot_vels[:, start_idx:end_idx]\n",
    "        pos = self.pos[:, start_idx:end_idx]\n",
    "        hds = self.hds[:, start_idx:end_idx]\n",
    "\n",
    "        embs_labels = self.embs[:, start_idx+1 : end_idx+1]\n",
    "        \n",
    "        return embs, vels, rot_vels, pos, hds, embs_labels\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17556bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the test data and process it into a dataloader, just like we did in the last part.\n",
    "\n",
    "STRIDE = 10\n",
    "d = './data/adult'\n",
    "trial_paths = sorted([p for p in Path(d).iterdir() if 'exp' in p.name])\n",
    "trial_paths\n",
    "\n",
    "\n",
    "test_embeddings = []\n",
    "test_vel, test_rotvel, test_pos, test_hds = [], [], [], []\n",
    "\n",
    "for idx in range(20, 23):\n",
    "    tp = trial_paths[idx]\n",
    "    test_embeddings.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'vision_embeddings.npy'), stride=STRIDE)\n",
    "    )\n",
    "    test_vel.append(\n",
    "        create_multiple_subsampling(\n",
    "            np.load(tp / 'riab_simulation' / 'velocities.npy'), stride=STRIDE, is_velocity=True\n",
    "        )\n",
    "    )\n",
    "    test_rotvel.append(\n",
    "        create_multiple_subsampling(\n",
    "            np.load(tp / 'riab_simulation' / 'rot_velocities.npy')[..., None],\n",
    "            stride=STRIDE, is_velocity=True\n",
    "        )\n",
    "    )\n",
    "    test_pos.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'riab_simulation' / 'positions.npy'), stride=STRIDE)\n",
    "    )\n",
    "    test_hds.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'riab_simulation' / 'thetas.npy')[..., None], stride=STRIDE)\n",
    "    )\n",
    "\n",
    "test_embeddings = np.concatenate(test_embeddings, axis=0)\n",
    "test_vel = np.concatenate(test_vel, axis=0)\n",
    "test_rotvel = np.concatenate(test_rotvel, axis=0)\n",
    "test_pos = np.concatenate(test_pos, axis=0)\n",
    "test_hds = np.concatenate(test_hds, axis=0)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    SensoryDataset(\n",
    "        test_embeddings, test_vel, test_rotvel, test_pos, test_hds\n",
    "    ), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5283f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's recreate the PredictiveRNN model, just like we did in the last part.\n",
    "visual_embedding_dim = test_embeddings.shape[-1]\n",
    "motion_signal_dim = test_vel.shape[-1] + test_rotvel.shape[-1]\n",
    "trained_rnn_weights ='./rnn.pth'\n",
    "\n",
    "rnn = PredictiveRNN(\n",
    "    DEVICE,\n",
    "    n_inputs=visual_embedding_dim + motion_signal_dim,\n",
    "    n_hidden=500,\n",
    "    n_outputs=visual_embedding_dim\n",
    ").to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "# load the trained weights\n",
    "rnn.load_state_dict(torch.load(trained_rnn_weights, map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd1748",
   "metadata": {},
   "source": [
    "### **2. Obtained hidden states from the trained RNN**\n",
    "\n",
    "We had written a function named ```evaluate_rnn()```, when the parameter ```for_ratemaps``` is set to ```True```, the function will return a dictionary containing the hidden staes, positions, velocities, etc. at each step for the convenience of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_rnn\n",
    "d = evaluate_rnn(DEVICE, rnn, test_dataloader, loss_fn, for_ratemaps=True)\n",
    "\n",
    "d['hidden_states'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ba3a1",
   "metadata": {},
   "source": [
    "### **3. Rate maps**\n",
    "\n",
    "The **rate map** of a neuron is essentially the average activity of a neuron across an environment. This is, by design, a continuous distribution.\n",
    "\n",
    "Computationally, this requires us to discritise the environment into smallers 'bins', then compute the average activity at each small bin. The function below computes such average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3205d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spatial_tuning_curves(hidden_states, pos, grid_size=(10,10)):\n",
    "    '''\n",
    "    Computes the spatial tuning curves of the neurons in the integrator RNN\n",
    "    :params:\n",
    "        hidden_states:      np.array, shape (num_instances, num_neurons), hidden states of the integrator RNN\n",
    "        pos:                np.array, shape (num_instances, 2), spatial position of the agent\n",
    "        grid_size:          tuple, discritisation size of the spatial field\n",
    "    '''\n",
    "\n",
    "    # Initialize arrays to hold tuning curves\n",
    "    cumulative_activation_at_each_bin = np.zeros((hidden_states.shape[1], grid_size[0], grid_size[1]))\n",
    "    occupancy_at_each_bin = np.ones((grid_size[0], grid_size[1]))\n",
    "\n",
    "    # aggregate neuron activity by spatial position\n",
    "    for i in range(pos.shape[0]):\n",
    "        cumulative_activation_at_each_bin = None\n",
    "        occupancy_at_each_bin = None\n",
    "        ### COMPLETE THE CODE HERE: convert the position to grid coordinates\n",
    "        # x, y = int(pos[i, 0] * (grid_size[0])), int(pos[i, 1] * (grid_size[1]))\n",
    "        # cumulative_activation_at_each_bin[:, x, y] += h_ts[i]\n",
    "        # occupancy_at_each_bin[x, y] += 1\n",
    "    \n",
    "    # COMPLETE THE CODE HERE: Compute tuning curve as the average activity at each spatial position\n",
    "    rate_map = None\n",
    "    # rate_map = cumulative_activation_at_each_bin / occupancy_at_each_bin\n",
    "\n",
    "    return rate_map, occupancy_at_each_bin\n",
    "\n",
    "rate_map, occupancy = compute_spatial_tuning_curves(\n",
    "    d['hidden_states'], d['pos'], grid_size=(10, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79d826",
   "metadata": {},
   "source": [
    "Let's now visualise a single rate map of the first neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de946776",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_rate_map = rate_map[0]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(one_rate_map, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Neuron activity')\n",
    "plt.title('Spatial Tuning Curve for Neuron 0')\n",
    "plt.xlabel('X Position (Grid)')\n",
    "plt.ylabel('Y Position (Grid)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b7229",
   "metadata": {},
   "source": [
    "In the real brain, neuron firings are stochastic. This means there is a lot of noise in the process, and the average activity of each bin is a crude (but unbiased) estimate of the real tuning curve, depending on the amount of data provided.\n",
    "\n",
    "Often, we make the assumption that a neuron's activity do not change too much in neighbouring bins. To make our rate maps look smoother, it is customary to apply **Gaussian smoothing** to the rate maps. This is easily achievable with packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921101dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "smoothened_rate_map = gaussian_filter(one_rate_map, sigma=2) # this means apply a Gaussian filter with a standard deviation of 2 bins\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(smoothened_rate_map, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Neuron activity')\n",
    "plt.title('Smoothened Spatial Tuning Curve for Neuron 0')\n",
    "plt.xlabel('X Position (Grid)')\n",
    "plt.ylabel('Y Position (Grid)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: we can plot 100 rate maps at once here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48da58",
   "metadata": {},
   "source": [
    "### **4. Polar maps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f66df",
   "metadata": {},
   "source": [
    "Comparable to rate maps, the **polar maps** show how a neuron fires when it is tuned to a specific angle (the head direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c591c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6447599c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
