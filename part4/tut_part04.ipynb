{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cc828c",
   "metadata": {},
   "source": [
    "---\n",
    "# Modelling hippocampal neurons of animals <br> navigating in VR with recurrent neural networks\n",
    "### Marco P. Abrate, Daniel Liu &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; University College London (UCL)\n",
    "---\n",
    "\n",
    "#### Outline\n",
    "**Part 1: Rat simulation in 3D**\n",
    "- Motion model with `RatInABox`\n",
    "\n",
    "- Environment design\n",
    "\n",
    "- Simulated rat vision with `ratvision`\n",
    "\n",
    "**Part 2: Vision autoencoder**\n",
    "\n",
    "**Part 3: Hippocampus model with RNN**\n",
    "\n",
    "**Part 4: Hidden state representations analysis**\n",
    "- Rate maps\n",
    "\n",
    "- Polar maps\n",
    "\n",
    "- Quantitive metrics\n",
    "\n",
    "- Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124450f7",
   "metadata": {},
   "source": [
    "---\n",
    "## **Part 4: Hidden state representations analysis**\n",
    "In this notebook, we will write code to extract representations from the **RNN hidden states**. These includes:\n",
    "- Rate maps\n",
    "- Polar maps\n",
    "- Quantitative metrics\n",
    "- Applications\n",
    "\n",
    "Before starting this notebook, make sure you have:\n",
    "- trajectory data from part 1, including speed and rotational speed\n",
    "- embedded vision data from the Vision Autoencoder we trained in part 2\n",
    "- RNN model of the hippocampus we trained in part 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00121d04",
   "metadata": {},
   "source": [
    "### 0. Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c292c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    \n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8a4ca",
   "metadata": {},
   "source": [
    "### 1. Load evaluation data and trained RNN\n",
    "\n",
    "As a first step, we will import the definitions of the RNN we coded in part 3, and load the trained weights. We will also load the embeddings of the data we will use to evaluate the hidden state representations, and some auxiliary variables that we will use to compute the rate maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_multiple_subsampling, SensoryDataset, PredictiveRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17556bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the test data and process it into a dataloader, just like we did in the last part.\n",
    "\n",
    "STRIDE = 10\n",
    "d = '../data/adult'\n",
    "trial_paths = sorted([p for p in Path(d).iterdir() if 'exp' in p.name])\n",
    "\n",
    "repr_embeddings = []\n",
    "repr_vel, repr_rotvel, repr_pos, repr_hds = [], [], [], []\n",
    "\n",
    "for idx in range(20, len(trial_paths)):\n",
    "    tp = trial_paths[idx]\n",
    "    repr_embeddings.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'vision_embeddings.npy'), stride=STRIDE)\n",
    "    )\n",
    "    repr_vel.append(\n",
    "        create_multiple_subsampling(\n",
    "            np.load(tp / 'riab_simulation' / 'velocities.npy'), stride=STRIDE, is_velocity=True\n",
    "        )\n",
    "    )\n",
    "    repr_rotvel.append(\n",
    "        create_multiple_subsampling(\n",
    "            np.load(tp / 'riab_simulation' / 'rot_velocities.npy')[..., None],\n",
    "            stride=STRIDE, is_velocity=True\n",
    "        )\n",
    "    )\n",
    "    repr_pos.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'riab_simulation' / 'positions.npy'), stride=STRIDE)\n",
    "    )\n",
    "    repr_hds.append(\n",
    "        create_multiple_subsampling(np.load(tp / 'riab_simulation' / 'thetas.npy')[..., None], stride=STRIDE)\n",
    "    )\n",
    "\n",
    "repr_embeddings = np.concatenate(repr_embeddings, axis=0)\n",
    "repr_vel = np.concatenate(repr_vel, axis=0)\n",
    "repr_rotvel = np.concatenate(repr_rotvel, axis=0)\n",
    "repr_pos = np.concatenate(repr_pos, axis=0)\n",
    "repr_hds = np.concatenate(repr_hds, axis=0)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    SensoryDataset(\n",
    "        repr_embeddings, repr_vel, repr_rotvel, repr_pos, repr_hds\n",
    "    ), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1736376",
   "metadata": {},
   "source": [
    "Let's re-define the `PredictiveRNN` model, just like we did in the last part, and load the trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5283f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDEN = 500\n",
    "\n",
    "visual_embedding_dim = repr_embeddings.shape[-1]\n",
    "motion_signal_dim = repr_vel.shape[-1] + repr_rotvel.shape[-1]\n",
    "trained_rnn_weights = '../part3/rnn.pth'\n",
    "\n",
    "rnn = PredictiveRNN(\n",
    "    DEVICE,\n",
    "    n_inputs = visual_embedding_dim + motion_signal_dim,\n",
    "    n_hidden = N_HIDDEN,\n",
    "    n_outputs = visual_embedding_dim\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "# load the trained weights\n",
    "rnn.load_state_dict(torch.load(trained_rnn_weights, weights_only=True, map_location=DEVICE))\n",
    "rnn = rnn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd1748",
   "metadata": {},
   "source": [
    "### 2. Get hidden states from trained RNN\n",
    "\n",
    "In the previous part, we wrote a function named `evaluate_rnn()` that &mdash; when the parameter `for_ratemaps` is set to `True` &mdash; will return a dictionary containing the hidden staes, positions, head directions, velocities, etc. at each time-step for convenience of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_rnn\n",
    "\n",
    "d = evaluate_rnn(DEVICE, rnn, dataloader, loss_fn, for_ratemaps=True)\n",
    "\n",
    "hidden_states = d['hidden_states']\n",
    "positions = d['positions']\n",
    "head_directions = d['head_directions']\n",
    "\n",
    "# Reshape the hidden states, positions, and head directions to\n",
    "# flatten out the number of trials dimension and keep (timesteps, features)\n",
    "hidden_states = hidden_states.reshape(-1, hidden_states.shape[-1])\n",
    "positions = positions.reshape(-1, positions.shape[-1])\n",
    "head_directions = head_directions.reshape(-1, head_directions.shape[-1])\n",
    "\n",
    "print(\n",
    "    'RNN loss (check it does not deviate too much from previous part figure):',\n",
    "    np.round(np.mean(d['batch_losses']), 2)\n",
    ")\n",
    "print(\n",
    "    'Hidden state, positions, and head directions shapes:\\n',\n",
    "    hidden_states.shape, positions.shape, head_directions.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ba3a1",
   "metadata": {},
   "source": [
    "### 3. Rate maps\n",
    "\n",
    "The **rate map** of a neuron is the two-dimensional representation of firing rates (or activity in our case) across spatial locations. In the real brain, neuron firings are stochastic. This means there is a lot of noise in the process, and the average activity of each bin is a crude (but unbiased) estimate of the real tuning curve, depending on the amount of data provided. The use of rate maps is standard practice in neuroscience for analysing place cell recordings [1].\n",
    "\n",
    "We divide the arena into a 25x25 grid (625 bins) and calculate the rate map R for each unit k by averaging unit activity within each spatial bin:\n",
    "\n",
    "$$\n",
    "    R_{i,j}^{(k)} = \\frac{\\sum_t A_t^{(k)} \\cdot\\overrightarrow{1}_{\\mathbf{p}_t \\in \\text{Bin}_{(i,j)}}}{\\sum_t \\overrightarrow{1}_{\\mathbf{p}_t \\in \\text{Bin}_{(i,j)}}}\\quad i, j \\in \\{1, \\dots, B_p\\}\\times \\{1, \\dots, B_p\\}\n",
    "$$\n",
    "\n",
    "where $A^{(k)}$ is the activity of hidden unit $k$, $\\mathbf{p}$ is the agent's position vector (x and y components), and $B_p$ is the number of bins along each direction.\n",
    "\n",
    "Computationally, it requires to discretise the environment into smallers bins &mdash; see `bin_data()` &mdash; then compute the average activity at each bin &mdash; see `compute_rate_maps()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3205d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def bin_data(data, n_bins, limits, weights=[]):\n",
    "    \"\"\"\n",
    "    Creates an N-dimensional histogram of data using n_bins between limits.\n",
    "    If weights is provided, it creates a weighted histogram.\n",
    "    \n",
    "    Args:\n",
    "        data: The data to be binned of shape (n_samples, n_dim).\n",
    "        n_bins: The number of bins for each dimension.\n",
    "        limits (list of tuples): The lower and upper limits for each dimension.\n",
    "        weights: 1D array-like, optional\n",
    "            The weights for the counts in the histogram.\n",
    "    \n",
    "    Returns:\n",
    "        binned_data: The N-dimensional histogram of data.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_dim = data.shape[-1]\n",
    "    if np.size(n_bins) < n_dim:\n",
    "        n_bins = np.repeat(n_bins, n_dim)\n",
    "    \n",
    "    bins = []\n",
    "    if n_dim == 1:\n",
    "        bins.append(np.linspace(limits[0], limits[1], n_bins+1))\n",
    "    else:\n",
    "        for i in range(n_dim):\n",
    "            bins.append(np.linspace(limits[i][0], limits[i][1], n_bins[i]+1))\n",
    "        \n",
    "    if len(weights) == 0:\n",
    "        hst = np.histogramdd(data, bins=bins)\n",
    "    else:\n",
    "        hst = np.histogramdd(data, bins=bins, weights=weights, density=False)\n",
    "\n",
    "    return hst[0]\n",
    "\n",
    "\n",
    "def compute_rate_maps(\n",
    "    hidden_states:np.array, pos:np.array, sigma:float,\n",
    "    n_bins:int, limits=[(0, 0.635),(0, 0.635)]\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the smooth rate map for each neuron based on the given hidden states and trajectory.\n",
    "\n",
    "    Args:\n",
    "        hidden_states (np.array): (timesteps, n_hidden) Array of hidden states for each neuron.\n",
    "        pos (np.array): (timesteps, 2) Array of (x,y) positions.\n",
    "        sigma (float): Standard deviation of the Gaussian filter.\n",
    "        n_bins (float): Number of bins for the positions.\n",
    "        limits (list): Lower and upper limits of the positions.\n",
    "\n",
    "    Returns:\n",
    "        rate_maps (np.array): Rate maps for each neuron of shape (n_hidden, n_bins, n_bins).\n",
    "        occupancy (np.array): Occupancy map of shape (n_bins, n_bins).\n",
    "    \"\"\"\n",
    "    \n",
    "    occupancy = bin_data(pos, n_bins=n_bins, limits=limits)\n",
    "    if sigma > 0:\n",
    "        occupancy = gaussian_filter(occupancy,sigma)\n",
    "\n",
    "    n_cells = hidden_states.shape[1]\n",
    "    rate_maps = np.empty(shape=(n_cells,occupancy.shape[0],occupancy.shape[1]))\n",
    "    for i in range(n_cells):\n",
    "        # YOUR CODE HERE (1)\n",
    "        # calculate the activations for each cell, for each binned position\n",
    "        activations = None\n",
    "        \n",
    "        # YOUR CODE HERE (2)\n",
    "        # obtain the rate map for each cell by dividing the activations by the occupancy\n",
    "        rate_maps[i,:,:] = None\n",
    "    \n",
    "    # flip y and swap x and y coordinates so\n",
    "    # that they appear correctly in the image\n",
    "    rate_maps = np.flip(rate_maps, axis=-1)\n",
    "    rate_maps = np.transpose(rate_maps, (0, 2, 1))\n",
    "\n",
    "    return rate_maps, occupancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee70a0",
   "metadata": {},
   "source": [
    "Often, we make the assumption that a neuron's activity doesn't change too much in neighbouring bins. To make our rate maps look smoother, it is customary to apply **Gaussian smoothing** to the rate maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb44229",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BINS = 25\n",
    "\n",
    "rate_maps, occupancy = compute_rate_maps(hidden_states, positions, n_bins=N_BINS, sigma=0)\n",
    "\n",
    "rate_maps_smooth, occupancy_smooth = compute_rate_maps(hidden_states, positions, n_bins=N_BINS, sigma=1.)\n",
    "\n",
    "print('Rate maps shape (n_hidden, n_bins, n_bins):', rate_maps_smooth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de946776",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(rate_maps[idx], cmap='jet')\n",
    "axs[0].set_title(f'Un-smoothed Rate Map for Neuron {idx}')\n",
    "axs[0].set_xlabel('X bin')\n",
    "axs[0].set_ylabel('Y bin')\n",
    "\n",
    "axs[1].imshow(rate_maps_smooth[idx], cmap='jet')\n",
    "axs[1].set_title(f'Smoothed Rate Map for Neuron {idx}')\n",
    "axs[1].set_xlabel('X bin')\n",
    "axs[1].set_ylabel('Y bin')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48da58",
   "metadata": {},
   "source": [
    "### 4. Polar maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f66df",
   "metadata": {},
   "source": [
    "Comparable to rate maps, the **polar maps** show how a neuron fires when it is tuned to a specific angle in polar space by binnind head direction into angular bins.\n",
    "\n",
    "The head direction space is divided into $B_\\theta = 60$ bins and $P^{(k)} \\in \\mathbb{R}^{B_\\theta}$ is calculated as\n",
    "$$\n",
    "P^{(k)}_{i} = \\frac{\\sum_t A_t^{(k)}~\\overrightarrow{1}_{\\theta_t \\in \\text{Bin}_i}}{\\sum_t \\overrightarrow{1}_{\\theta_t \\in \\text{Bin}_i}}, \\quad i \\in \\{1, \\dots, B_\\theta\\}\n",
    "$$\n",
    "Where $A^{(k)}_t$ is the hidden layer’s activity (or value) of unit $k$ and $\\theta$ is the agent's head direction.\n",
    "\n",
    "**Note**: In this notebook, we use the terms _head direction_ and _theta_ interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1653ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_polar_maps(\n",
    "    hidden_states:np.array, head_directions:np.array, sigma:float,\n",
    "    n_bins:int, limits=(-np.pi, np.pi)\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the (smooth) polar map for each neuron based on the given hidden states and thetas.\n",
    "\n",
    "    Args:\n",
    "        hidden_states (np.array): (samples, n_hidden) Array of hidden states for each neuron.\n",
    "        head_directions (np.array): (samples,) Array of head direction points.\n",
    "        sigma (float, optional): Standard deviation of the circular filter. Defaults to 5.\n",
    "        n_bins (float): Number of angular bins for the head directions.\n",
    "        limits (tuple, optional): Limits of the hd space. Defaults to (-np.pi, np.pi).\n",
    "\n",
    "    Returns:\n",
    "        polar_maps (np.array): Array of polar maps for each neuron of shape (n_hidden, n_bins).\n",
    "        occupancy (np.array): Occupancy map of shape (n_bins,).\n",
    "    \"\"\"\n",
    "    \n",
    "    occupancy = bin_data(head_directions, n_bins=n_bins, limits=limits)\n",
    "    if sigma > 0:\n",
    "        occupancy = gaussian_filter(occupancy, sigma, mode='wrap')\n",
    "\n",
    "    n_cells = hidden_states.shape[1]\n",
    "    polar_maps = np.empty(shape=(n_cells,occupancy.shape[0]))\n",
    "    for i in range(n_cells):\n",
    "        # YOUR CODE HERE (3)\n",
    "        # calculate the activations for each cell, for each binned head direction\n",
    "        activations = None\n",
    "        \n",
    "        # YOUR CODE HERE (4)\n",
    "        # obtain the polar map for each cell by dividing the activations by the occupancy\n",
    "        polar_maps[i] = None\n",
    "\n",
    "    return polar_maps, occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BINS_POLAR = 60\n",
    "bins_thet = np.linspace(-np.pi, np.pi, N_BINS_POLAR+1)\n",
    "thetas_ticks = np.array(\n",
    "    [np.mean([a, b]) for a, b in zip(bins_thet, bins_thet[1:])]\n",
    ")\n",
    "bins_thet = bins_thet[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39328beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_maps, polar_occupancy = compute_polar_maps(\n",
    "    hidden_states, head_directions, n_bins=N_BINS_POLAR, sigma=0.\n",
    ")\n",
    "\n",
    "polar_maps_smooth, polar_occupancy_smooth = compute_polar_maps(\n",
    "    hidden_states, head_directions, n_bins=N_BINS_POLAR, sigma=2.5\n",
    ")\n",
    "\n",
    "print('Polar maps shape (n_hidden, n_bins):', polar_maps_smooth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2168a2",
   "metadata": {},
   "source": [
    "Let's plot the polar map of the same neuron. Note that we will need to use the polar projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c406e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "axs[0].plot(\n",
    "    np.append(thetas_ticks, thetas_ticks[0]), # we want to close the circle\n",
    "    np.append(polar_maps[idx], polar_maps[idx][0]), # we want to close the circle\n",
    "    lw=3, c='blue',\n",
    ")\n",
    "# axs[0].set_xticklabels([]) # remove degrees indication\n",
    "axs[0].set_rticks([max(polar_maps[idx])], labels=[f\"{max(polar_maps[idx]):.2f}\"]) # add intensity indication\n",
    "axs[0].tick_params(axis='y', labelsize=9)\n",
    "axs[0].set_theta_direction(-1)\n",
    "axs[0].set_theta_zero_location('N') # move 0 to the north\n",
    "axs[0].grid(True)\n",
    "axs[0].set_title(f'Un-smoothed Polar Map for Neuron {idx}')\n",
    "\n",
    "axs[1].plot(\n",
    "    np.append(thetas_ticks, thetas_ticks[0]), # we want to close the circle\n",
    "    np.append(polar_maps_smooth[idx], polar_maps_smooth[idx][0]), # we want to close the circle\n",
    "    lw=3, c='blue',\n",
    ")\n",
    "axs[1].set_rticks(\n",
    "    [max(polar_maps_smooth[idx])],\n",
    "    labels=[f\"{max(polar_maps_smooth[idx]):.2f}\"]\n",
    ") # add intensity indication\n",
    "axs[1].tick_params(axis='y', labelsize=9)\n",
    "axs[1].set_theta_direction(-1)\n",
    "axs[1].set_theta_zero_location('N') # move 0 to the north\n",
    "axs[1].grid(True)\n",
    "axs[1].set_title(f'Smoothed Polar Map for Neuron {idx}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447599c",
   "metadata": {},
   "source": [
    "### 5. Spatial metrics\n",
    "\n",
    "In this part we will examine some commonly used metrics used to quantify and classify spatial cells, following standard neuroscience classification criteria [2, 3]. We quantify spatial and directional selectivity using spatial information (SI) and resultant vector length (RVL), respectively. We compute these metrics on min-max normalised rate and polar maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35920f5c",
   "metadata": {},
   "source": [
    "**Spatial information (SI)** measures how much information (in bits) a cell's firing conveys about the agent's position per spike [4].\n",
    "\n",
    "Given\n",
    "- $B \\quad\\rightarrow$ number of bins\n",
    "\n",
    "- $R_i \\quad\\rightarrow$ value of the rate map at bin $i$\n",
    "\n",
    "- $p_i \\quad\\rightarrow$ probability of being in bin $i$ (occupancy probability)\n",
    "\n",
    "- $\\hat{R} = \\sum_{i=1}^{B} p_i~R_i \\quad\\rightarrow$ overall mean activity\n",
    "\n",
    "Then\n",
    "$$\n",
    "\\text{SI}_{\\text{sec}} = \\sum_{i=1}^{B} p_i~R_i~\\log_2 \\left( \\frac{R_i}{\\hat{R}} \\right)\n",
    "$$\n",
    "measured in **bits per second**. We can convert the SI in **bits per spike** dividing by the mean rate:\n",
    "$$\n",
    "\\text{SI}_{\\text{spike}} = \\frac{\\text{SI}_{\\text{sec}}}{\\hat{R}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_information(rate_map: np.ndarray, occupancy: np.ndarray):\n",
    "    \"\"\"\n",
    "    Calculates the Spatial Information (SI) for a given rate map.\n",
    "\n",
    "    Args:\n",
    "        rate_map (np.array): (n_bins, n_bins) Rate map of a single neuron.\n",
    "        occupancy (np.array): occupancy map of shape (n_bins,).\n",
    "\n",
    "    Returns:\n",
    "        si (float): Spatial information content of the rate map.\n",
    "    \"\"\"\n",
    "    # discard bins where occupancy is zero or NaN\n",
    "    no_occ = np.logical_or(occupancy == 0, np.isnan(occupancy))\n",
    "    _rate = rate_map[~no_occ]\n",
    "    _occ = occupancy[~no_occ]\n",
    "\n",
    "    # calculate total duration and occupancy probability\n",
    "    duration = np.sum(_occ)\n",
    "    _occ_prob = _occ / duration\n",
    "\n",
    "    # calculate mean firing rate\n",
    "    _rate_mean = np.sum(_rate*_occ) / duration\n",
    "\n",
    "    mask = _rate > 0\n",
    "\n",
    "    # YOUR CODE HERE (5)\n",
    "    # use the equation above, calculate the SI (assuming we are measuring in bits per second)\n",
    "    si = None\n",
    "\n",
    "\n",
    "    return si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_maps_min = np.moveaxis(\n",
    "    np.tile(np.nanmin(rate_maps_smooth, axis=(1,2)), (N_BINS, N_BINS, 1)), -1, 0\n",
    ")\n",
    "rate_maps_max = np.moveaxis(\n",
    "    np.tile(np.nanmax(rate_maps_smooth, axis=(1,2)), (N_BINS, N_BINS, 1)), -1, 0\n",
    ")\n",
    "rate_maps_norm = np.divide(\n",
    "    (rate_maps_smooth - rate_maps_min),\n",
    "    (rate_maps_max - rate_maps_min),\n",
    "    where=np.logical_and(\n",
    "        (rate_maps_max - rate_maps_min)!=0,\n",
    "        ~np.isnan(rate_maps_smooth)\n",
    "    ),\n",
    "    out=rate_maps_smooth\n",
    ")\n",
    "\n",
    "# uniform_rate_map = np.ones_like(rate_maps_norm[0])/(n**2)\n",
    "# if occ is None : occ = uniform_rate_map\n",
    "\n",
    "si = np.array([spatial_information(rm, occupancy_smooth) for rm in rate_maps_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(si, bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Spatial Information')\n",
    "plt.xlabel('Spatial information')\n",
    "plt.ylabel('Number of neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4919d",
   "metadata": {},
   "source": [
    "**Resultant vector length (RVL)** measures the concentration of the directional preference.\n",
    "\n",
    "Given\n",
    "- $B \\quad\\rightarrow$ number of bins\n",
    "\n",
    "- $P_i \\quad\\rightarrow$ value of the polar map at bin $i$\n",
    "\n",
    "- $\\mathbf{r} = \\sum_{i=1}^B \\exp\\left(j\\frac{2\\pi}{B_\\theta}~i\\right)~P_i \\quad\\rightarrow$ resultant vector of polar map $P$, where $j$ is an imaginary unit.\n",
    "\n",
    "Then\n",
    "$$\n",
    "\\text{RVL} = \\frac{|\\mathbf{r}|}{\\sum_{i=1}^B P_i}\n",
    "$$\n",
    "\n",
    "$\\text{RVL}$ is a number between 0 and 1. \n",
    "\n",
    "If $\\text{RVL}$ is close to 1, it indicates **ideal directional tuning** (all weights concentrated at a single angle). If it is close to 0, then directional tuning is **uniform** around the circle. Otherwise, some degrees of directional concentration is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultant_vector(polar_map, bins, spacing):\n",
    "    \"\"\"\n",
    "    Calculate the resultant vector of a given set of angles.\n",
    "\n",
    "    Args:\n",
    "        polar_map (np.array): (n_bins,) Polar map of a single neuron.\n",
    "        bins (np.array): Array of angles.\n",
    "        spacing (float, optional): Known spacing between angles.\n",
    "    Returns:\n",
    "        rvl (float): Length of the resultant vector.\n",
    "        rv_angle (float): Angle of the resultant vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE (6)\n",
    "    # calculate resultant vector as sum of cos & sin angles\n",
    "    rv = None\n",
    "    \n",
    "    # calculate the angle of the resultant vector\n",
    "    rv_angle = np.angle(rv)\n",
    "\n",
    "    # get length\n",
    "    rvl = np.abs(rv) / np.sum(polar_map)\n",
    "\n",
    "    # for data with known spacing, apply correction factor to correct\n",
    "    # for bias in the estimation of r\n",
    "    # (see Biostatistical Analysis, J. H. Zar, p. 601, equ. 26.16)\n",
    "    rvl *= spacing / 2 / np.sin(spacing / 2)\n",
    "\n",
    "    return rvl, rv_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d037e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisor = np.moveaxis(\n",
    "    np.tile(polar_maps_smooth.sum(axis=1), (N_BINS_POLAR, 1)), -1, 0\n",
    ")\n",
    "polar_maps_norm = np.divide(\n",
    "    polar_maps_smooth, divisor,\n",
    "    where=divisor != 0, out=polar_maps_smooth\n",
    ")\n",
    "\n",
    "rv_tuple = [\n",
    "    resultant_vector(\n",
    "        polar_map=pm,\n",
    "        bins=bins_thet,\n",
    "        spacing=2*np.pi/N_BINS_POLAR\n",
    "    ) for pm in polar_maps_norm\n",
    "]\n",
    "\n",
    "rvl = np.array([x[0] for x in rv_tuple])\n",
    "rvangle = np.array([x[1] for x in rv_tuple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(rvl, bins=30, color='blue', alpha=0.7)\n",
    "plt.xlabel('Resultant Vector Length')\n",
    "plt.ylabel('Number of Neurons')\n",
    "plt.title('Distribution of Resultant Vector Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698428a",
   "metadata": {},
   "source": [
    "### 6. Spatial neurons\n",
    "\n",
    "Following standard neuroscience classification criteria [2, 3], we will identify **place cells** based on these two criteria:\n",
    "\n",
    "* Spatial information > 0.3\n",
    "\n",
    "* Place fields are contiguous (we define a place field here as a bin with mean firing rate greater than 95% quantile of that neuron)\n",
    "\n",
    "We will classify **head directional cells** on whose RVL is greater than 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_if_contiguous\n",
    "\n",
    "# classify neurons as place cells based on spatial information\n",
    "indices_place = np.where(si>0.3)[0]\n",
    "\n",
    "# filter discontiguous place fields\n",
    "for i in indices_place:\n",
    "    place_fields = [tuple(x) for x in np.argwhere(rate_maps_norm[i] > np.quantile(rate_maps_norm[i], 0.95)).tolist()]\n",
    "    if check_if_contiguous(place_fields, tolerance=1) is False:\n",
    "        indices_place = np.delete(indices_place, np.where(indices_place == i))\n",
    "\n",
    "print('Number of place cells:', len(indices_place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 100\n",
    "indices = np.random.choice(indices_place, size=n_plot, replace=False)\n",
    "\n",
    "n_rows = int(np.ceil(n_plot/10))\n",
    "fig, axs = plt.subplots(n_rows, 10, figsize=(12, n_rows*1.5))\n",
    "\n",
    "for idx in range(n_plot):\n",
    "    ax = axs.flat[idx]\n",
    "    ax.imshow(rate_maps_smooth[indices[idx]], cmap='jet')\n",
    "    ax.set_title(f'Neuron {indices[idx]}', fontsize='small')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a76cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_hd = np.where(rvl>0.35)[0]\n",
    "\n",
    "print('Number of head direction cells:', len(indices_hd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8516dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 100\n",
    "indices = np.random.choice(indices_hd, size=n_plot, replace=False)\n",
    "\n",
    "n_rows = int(np.ceil(n_plot/10))\n",
    "fig, axs = plt.subplots(n_rows, 10, figsize=(12, n_rows*1.5), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for idx in range(n_plot):\n",
    "    ax = axs.flat[idx]\n",
    "    polar_map = polar_maps_smooth[indices[idx]]\n",
    "\n",
    "    ax.plot(\n",
    "        np.append(thetas_ticks, thetas_ticks[0]), # we want to close the circle\n",
    "        np.append(polar_map, polar_map[0]), # we want to close the circle\n",
    "        lw=3, c='blue',\n",
    "    )\n",
    "    ax.vlines(\n",
    "        rvangle[indices[idx]], 0, np.max(polar_map),\n",
    "        colors='red', lw=2\n",
    "    )\n",
    "    ax.set_rticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_theta_zero_location('N') # move 0 to the north\n",
    "    ax.grid(True)\n",
    "    ax.set_title(f'Neuron {indices[idx]}', fontsize='small')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014dd41f",
   "metadata": {},
   "source": [
    "### 7. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e5dca",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] R. U. Muller and J. L. Kubie. The firing of hippocampal place cells predicts the future position of freely moving rats. Journal of Neuroscience, 9(12):4101–4110, 1989.\n",
    "\n",
    "[2] J. O'Keefe and D. H. Conway. Hippocampal place units in the freely moving rat: why they fire where they fire. Experimental brain research, 31:573–590, 1978.\n",
    "\n",
    "[3] J. C. Whittington, T. 390 H. Muller, S. Mark, G. Chen, C. Barry, N. Burgess, and T. E. Behrens. The tolman-eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation. Cell, 183(5):1249–1263, 2020.\n",
    "\n",
    "[4] W. E. Skaggs, B. L. McNaughton, M. A. Wilson, and C. A. Barnes. Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences. Hippocampus, 6(2):149–172, 1996.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
